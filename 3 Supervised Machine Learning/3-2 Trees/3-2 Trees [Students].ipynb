{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Computational Social Science]\n",
    "## 3-2 Tree-Based Methods and Ensemble Methods - Student Version\n",
    "\n",
    "In this lab, we will explore decision trees and their extensions. We will also introduce ensemble machine learning, which involves combining several machine learning algorithms together to create a better modelË™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We're going to use our Census Income dataset dataset again for this lab. Load the dataset in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "#sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of column names, found in \"adult.names\"\n",
    "col_names = ['age', 'workclass', 'fnlwgt',\n",
    "            'education', 'education-num',\n",
    "            'marital-status', 'occupation', \n",
    "             'relationship', 'race', \n",
    "             'sex', 'capital-gain',\n",
    "            'capital-loss', 'hours-per-week',\n",
    "            'native-country', 'income-bracket']\n",
    "\n",
    "# Read table from the data folder\n",
    "census = pd.read_table(\"../../data/adult.data\", sep = ',', names = col_names)\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we need to preprocess the data to binarize the target and dummify our categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "lb_style = LabelBinarizer()\n",
    "y = census['income-bracket-binary'] = lb_style.fit_transform(census[\"income-bracket\"])\n",
    "\n",
    "# Features\n",
    "X = census.drop(['income-bracket', 'fnlwgt', 'income-bracket-binary'], axis = 1)\n",
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we will look at is the decision tree. Using the [`tree.DecisionTreeClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) method, let's implement a cross-validation approach to predicting income. We will initialize the model with the standard configurations from the Classification lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Decision Tree Classifier\n",
    "dt_classifier = tree.DecisionTreeClassifier(criterion='gini',  # or 'entropy' for information gain\n",
    "                       splitter='best',  # or 'random' for random best split\n",
    "                       max_depth=None,  # how deep tree nodes can go\n",
    "                       min_samples_split=2,  # samples needed to split node\n",
    "                       min_samples_leaf=1,  # samples needed for a leaf\n",
    "                       min_weight_fraction_leaf=0.0,  # weight of samples needed for a node\n",
    "                       max_features=None,  # number of features to look for when splitting\n",
    "                       max_leaf_nodes=None,  # max nodes\n",
    "                       min_impurity_decrease=1e-07, #early stopping\n",
    "                       random_state = 10)  #random seed\n",
    "                       #class_weight = \"balanced\") # balanced class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score returns the accuracy score by default but you can change this with the \"scoring\" argument\n",
    "scores = cross_val_score(dt_classifier, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the mean score from the results of cross validation\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".82 accuracy, not bad! We can also visualize the decision tree to see how it made its splits. Note we limit the max depth to 4 so that the code runs quickly, but in practice you might want to visualize the entire tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier.fit(X, y)\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(dt_classifier, \n",
    "                   feature_names=X.columns,  \n",
    "                   class_names=[\"<=50k\", \">50k\"],\n",
    "                   filled=True,\n",
    "                  fontsize = 10,\n",
    "                  max_depth = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the .max_depth attribute to check out the depth of our entire tree\n",
    "dt_classifier.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remind ourselves how many samples in our negative class\n",
    "np.count_nonzero(y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the samples after root node\n",
    "X['marital-status_ Married-civ-spouse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the most informative features\n",
    "importances = pd.DataFrame({'feature':X.columns,'importance':np.round(dt_classifier.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False)\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Authored by Aniket Kesari. Minor edits by Tom van Nuenen 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
