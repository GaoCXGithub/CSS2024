{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15ff7bd",
   "metadata": {},
   "source": [
    "# BART\n",
    "\n",
    "In this lab, we will cover BART. Bayesian Additive Regression Trees (BART) is a non-linear, non-parametric Bayesian statistical model. It's used for regression and classification problems and has been shown to provide flexible fits to complex datasets, often outperforming traditional methods like linear regression or classification and regression trees.\n",
    "\n",
    "BART models data as a sum of decision trees where each tree is constrained by a prior to be a weak learner, contributing a small amount to the overall prediction. This setup helps in avoiding overfitting, which is a common problem with methods that use decision trees, such as random forests.\n",
    "\n",
    "In more technical terms, given a response variable Y and predictor variables X1, X2, ..., Xp, BART assumes the following relationship:\n",
    "\n",
    "Y = f(X1, X2, ..., Xp) + e\n",
    "\n",
    "where f(X1, X2, ..., Xp) is an unknown function and e is a normally distributed error term. BART approximates the unknown function f by an additive model of binary trees.\n",
    "\n",
    "The \"Bayesian\" part of BART comes in because it uses Bayesian methods to learn from the data and make predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46500cc6",
   "metadata": {},
   "source": [
    "## Virtual Environment\n",
    "Remember to always activate your virtual environment first before you install packages or run a notebook! This helps to prevent conflicts between dependencies across different projects and ensures that you are using the correct versions of packages. You must have created anaconda virtual enviornment in the `Anaconda Installation` lab. If you have not or want to create a new virtual environment, follow the instruction in the `Anaconda Installation` lab. If you have already created a virtual enviornment, you can run the following command to activate it. <br>\n",
    "`conda activate <virtual_env_name>`\n",
    "For example, if your virtual environment was named as css_lab, run the following command. <br>\n",
    "`conda activate css_lab`\n",
    "To deactivate your virtual environment after you are done working with the lab, run the following command. <br>\n",
    "`conda deactivate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8736cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pymc\n",
    "#!pip3 install pymc_bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az #ArviZ is a Python package for exploratory analysis of Bayesian models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm #PyMC (formerly PyMC3) is a Python package for Bayesian statistical modeling\n",
    "import pymc_bart as pmb # PyMC-BART extends PyMC \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"Running on PyMC v{pm.__version__}\") #bart might not work in older version of pymc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefff6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 300\n",
    "np.random.seed(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c93fb",
   "metadata": {},
   "source": [
    "In this lab, we will first use coal mining disaster dataset. This is a popular dataset in the PYMC library documentation. We will discretize the dataset by building a histogram and use center of bins as x variable and counts per bin as y variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec02de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file \"coal.csv\" would be included in the PyMC library installation on your computer\n",
    "# As per the numpy.loadtxt() function, it expects the file to be a text file with numerical\n",
    "# data, and it will load this data into a NumPy array called coal. csv file is a type of text file.\n",
    "coal = np.loadtxt(pm.get_data(\"coal.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize data\n",
    "years = int(.. - ..) # calculates the range of the data. If the coal \n",
    "# dataset represents years, this would give the number of years the data spans.\n",
    "bins = years .. 4 # calculate the number of bins for the histogram by \n",
    "# performing floor division. \n",
    "hist, x_edges = np.histogram(coal, bins=bins) # hist will be an array with the number of\n",
    "# elements in each bin, and x_edges will be an array with the edge values of the bins.\n",
    "# compute the location of the centers of the discretized data\n",
    "\n",
    "x_centers = x_edges[:-1] + (x_edges[1] - x_edges[0]) / 2 #  calculates the centers of the\n",
    "# bins. It does this by adding half the bin width ((x_edges[1] - x_edges[0]) / 2) \n",
    "# to the left edges of the bins (x_edges[:-1]). This is done to represent each bin by\n",
    "#its center point rather than its edges.\n",
    "\n",
    "x_data = x_centers[:, None] # converts x_centers into a 2D array with one column. \n",
    "# The None indexing is used to add an extra dimension. This is done because the BART  \n",
    "# model expects 2D input.\n",
    "\n",
    "# just renames hist to y_data. This data represents the counts in each bin \n",
    "# (or the number of disasters per year).\n",
    "y_data = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_coal: # This line is creating a new probabilistic model using PyMC3. Everything that happens within the with block pertains to this model_coal.\n",
    "    μ_ = pmb.BART(\"μ_\", X=x_data, Y=np.log(y_data), m=20) # This line is defining a BART model with the predictor variable X set to x_data and the response variable Y set to np.log(y_data). The m=20 parameter is defining the number of trees to use in the BART model. The output of this model is being stored in μ_\n",
    "\n",
    "    \n",
    "    μ = pm.Deterministic(\"μ\", pm.math.exp(μ_)) # This line is defining a deterministic variable μ, which is the exponential of μ_. This is done because μ_ is on the log scale due to the np.log(y_data) used in the BART model.\n",
    "    y_pred = pm.Poisson(\"y_pred\", mu=μ, observed=y_data)\n",
    "    idata_coal = pm.sample(random_seed=RANDOM_SEED)# sample from the posterior distribution of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a254e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 6)) # The underscore (_) is a common convention in Python for a variable name that we don't plan to use.\n",
    "\n",
    "rates = idata_coal.posterior[\"μ\"] / 4\n",
    "rate_mean = rates.mean(dim=[\"draw\", \"chain\"])\n",
    "ax.plot(x_centers, rate_mean, \"w\", lw=3)\n",
    "ax.plot(x_centers, y_data / 4, \"k.\")\n",
    "az.plot_hdi(x_centers, rates, smooth=False)\n",
    "az.plot_hdi(x_centers, rates, hdi_prob=0.5, smooth=False, plot_kwargs={\"alpha\": 0})\n",
    "ax.plot(coal, np.zeros_like(coal) - 0.5, \"k|\")\n",
    "ax.set_xlabel(\"years\")\n",
    "ax.set_ylabel(\"rate\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baa52ec",
   "metadata": {},
   "source": [
    "The white line in the plot above shows the median rate of accidents. The darker orange band represent the HDI 50% and the lighter one the 94%. \n",
    "\n",
    "# Discussion\n",
    "Interpret the plot above. Do you see any rapid increase or decrease in coal accidents between a given time range? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abedf00",
   "metadata": {},
   "source": [
    "# \n",
    "The following figure shows two samples from the posterior of\n",
    "μ. We can see that these functions are not smooth. This is fine and is a direct consequence of using regression trees. Trees can be seen as a way to represent stepwise functions, and a sum of stepwise functions is just another stepwise function. Thus, when using BART we just need to know that we are assuming that a stepwise function is a good enough approximation for our problem. In practice this is often the case because we sum over many trees, usually values like 50, 100 or 200. Additionally, we often average over the posterior distribution. All this makes the “steps smoother”, even when we never really have an smooth function as for example with Gaussian processes (splines). A nice theoretical result, tells us that in the limit of **m -> ∞** . \n",
    "the BART prior converges to a [nowheredifferentiable](https://en.wikipedia.org/wiki/Weierstrass_function) Gaussian process.\n",
    "\n",
    "\n",
    "The following figure shows two samples of μ\n",
    "from the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.step(x_data, rates.sel(chain=0, draw=[3, 10]).T);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4aaeb1",
   "metadata": {},
   "source": [
    "Now let's explore BART using four covariate using a subset of popular bike sharing dataset.\n",
    "We will use the following variables: number of bike rental in a city, the hour of the day, the temperature, the humidity, and whether it is a weekday or weekend. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to read csv file\n",
    "bikes = ..(pm.get_data(\"bikes.csv\"))  # the file bikes.csv is included in pymc installation\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab0391",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"hour\", \"temperature\", \"humidity\", \"workingday\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bikes[..]  # store subset of bikes dataframe by using only columns whose name are stored in 'features' list\n",
    "Y = bikes[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_bikes:\n",
    "    α = pm.Exponential(\"α\", 1)\n",
    "    μ = pmb.BART(\"μ\", X, np.log(Y), m=50)\n",
    "    y = pm.NegativeBinomial(\"y\", mu=pm.math.exp(μ), alpha=α, observed=Y)\n",
    "    idata_bikes = pm.sample(compute_convergence_checks=False, random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67070154",
   "metadata": {},
   "source": [
    "# Partial dependence plots\n",
    "\n",
    "To aid in the interpretation of our model's results, we will employ partial dependence plots. These plots demonstrate the marginal effect of one covariate on the predicted variable. PyMC-BART provides an utility function to make this plot from the inference data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmb.plot_pdp(μ, X=X, Y=Y, grid=(2, 2), func=np.exp) # explore plot_pdp function futher at https://github.com/pymc-devs/pymc-bart/blob/main/pymc_bart/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c6f87a",
   "metadata": {},
   "source": [
    "# Disucssion\n",
    "From the plot above, we can see the main effect of each covariate on the predicted value. \n",
    "Discuss if you notice any peak in the graph and what those might represent? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe35046",
   "metadata": {},
   "source": [
    "### Acknowledgement\n",
    "The lab was adapted from the following official documentation in PyMC. https://www.pymc.io/projects/examples/en/latest/case_studies/BART_introduction.html Please explore the official documentation if you want to learn more. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
