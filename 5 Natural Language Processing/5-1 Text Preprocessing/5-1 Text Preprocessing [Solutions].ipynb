{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Computational Social Science]\n",
    "## 5-1 Text Preprocessing and Featurization - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab will cover the basics of text preprocessing and featurization, and introduce text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual Environment\n",
    "Remember to always activate your virtual environment first before you install packages or run a notebook! This prevents the potential of crashing your root Python/Anaconda installation. You must have created anaconda virtual enviornment in the `Anaconda Installation` lab. If you have not or want to create a new virtual environment, follow the instruction in the `Anaconda Installation` lab. If you have already created a virtual enviornment, you can run the following command to activate it. <br>\n",
    "`conda activate <virtual_env_name>`\n",
    "For example, if your virtual environment was named as legal-studies, run the following command. <br>\n",
    "`conda activate legal-studies`\n",
    "To deactivate your virtual environment after you are done working with the lab, run the following command. <br>\n",
    "`conda deactivate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"../../images/cfpb logo.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next few labs, we will use the Consumer Financial Protection Bureau's [Consumer Complaint Database](https://www.consumerfinance.gov/data-research/consumer-complaints/). The database is rich with information about individual consumer complaints about credit card fraud, debt collections, and other consumer issues. This dataset is convenient for text analysis because the consumer complaints are real text generated by real people - and have all the idiosyncrasies that come with that process. It also contains multiple different categories that we can predict, like type of product the complaint is about and whether the complaint was resolved quickly. The basic process is that if someone has a dispute related to consumer finance (mortgages, student loans, credit cards, etc.), they can file a dispute with the CFPB, which then contacts the company named in the dispute to get some resolution of the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfpb = pd.read_csv(\"../../data/CFPB 2020 Complaints.csv\")\n",
    "cfpb = cfpb.dropna(subset = ['Consumer complaint narrative']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>01/30/20</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>Investigation took more than 30 days</td>\n",
       "      <td>Reviewed my credit report in XX/XX/XXXX and no...</td>\n",
       "      <td>None</td>\n",
       "      <td>EQUIFAX, INC.</td>\n",
       "      <td>AZ</td>\n",
       "      <td>850XX</td>\n",
       "      <td>None</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>01/30/20</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3515096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>03/12/20</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account status incorrect</td>\n",
       "      <td>TransUnion has not properly investigated the i...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>IL</td>\n",
       "      <td>606XX</td>\n",
       "      <td>None</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>03/12/20</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3564439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>05/01/20</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>Their investigation did not fix an error on yo...</td>\n",
       "      <td>XX/XX/2020 someone tried to steal my identity ...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>IL</td>\n",
       "      <td>606XX</td>\n",
       "      <td>None</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>05/01/20</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3633318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>04/06/20</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Other debt</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Debt was paid</td>\n",
       "      <td>I paid the debt on XX/XX/XXXX. I disputed acco...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>NY</td>\n",
       "      <td>None</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>04/06/20</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3594679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>04/18/20</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>A COLLECTION HAS BEEN REPORTED TO MY CREDIT RE...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>Convergent Resources, Inc.</td>\n",
       "      <td>FL</td>\n",
       "      <td>336XX</td>\n",
       "      <td>None</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>04/18/20</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3611900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Date received                                            Product  \\\n",
       "0      8      01/30/20  Credit reporting, credit repair services, or o...   \n",
       "1     10      03/12/20  Credit reporting, credit repair services, or o...   \n",
       "2     14      05/01/20  Credit reporting, credit repair services, or o...   \n",
       "3     19      04/06/20                                    Debt collection   \n",
       "4     35      04/18/20                                    Debt collection   \n",
       "\n",
       "        Sub-product                                              Issue  \\\n",
       "0  Credit reporting  Problem with a credit reporting company's inve...   \n",
       "1  Credit reporting               Incorrect information on your report   \n",
       "2  Credit reporting  Problem with a credit reporting company's inve...   \n",
       "3        Other debt                  Attempts to collect debt not owed   \n",
       "4     I do not know                  Attempts to collect debt not owed   \n",
       "\n",
       "                                           Sub-issue  \\\n",
       "0               Investigation took more than 30 days   \n",
       "1                           Account status incorrect   \n",
       "2  Their investigation did not fix an error on yo...   \n",
       "3                                      Debt was paid   \n",
       "4                                  Debt is not yours   \n",
       "\n",
       "                        Consumer complaint narrative  \\\n",
       "0  Reviewed my credit report in XX/XX/XXXX and no...   \n",
       "1  TransUnion has not properly investigated the i...   \n",
       "2  XX/XX/2020 someone tried to steal my identity ...   \n",
       "3  I paid the debt on XX/XX/XXXX. I disputed acco...   \n",
       "4  A COLLECTION HAS BEEN REPORTED TO MY CREDIT RE...   \n",
       "\n",
       "                             Company public response  \\\n",
       "0                                               None   \n",
       "1  Company has responded to the consumer and the ...   \n",
       "2  Company has responded to the consumer and the ...   \n",
       "3  Company has responded to the consumer and the ...   \n",
       "4  Company has responded to the consumer and the ...   \n",
       "\n",
       "                                  Company State ZIP code           Tags  \\\n",
       "0                           EQUIFAX, INC.    AZ    850XX           None   \n",
       "1  TRANSUNION INTERMEDIATE HOLDINGS, INC.    IL    606XX           None   \n",
       "2  TRANSUNION INTERMEDIATE HOLDINGS, INC.    IL    606XX           None   \n",
       "3     Experian Information Solutions Inc.    NY     None  Servicemember   \n",
       "4              Convergent Resources, Inc.    FL    336XX           None   \n",
       "\n",
       "  Consumer consent provided? Submitted via Date sent to company  \\\n",
       "0           Consent provided           Web             01/30/20   \n",
       "1           Consent provided           Web             03/12/20   \n",
       "2           Consent provided           Web             05/01/20   \n",
       "3           Consent provided           Web             04/06/20   \n",
       "4           Consent provided           Web             04/18/20   \n",
       "\n",
       "      Company response to consumer Timely response?  Consumer disputed?  \\\n",
       "0          Closed with explanation              Yes                 NaN   \n",
       "1          Closed with explanation              Yes                 NaN   \n",
       "2  Closed with non-monetary relief              Yes                 NaN   \n",
       "3          Closed with explanation              Yes                 NaN   \n",
       "4          Closed with explanation              Yes                 NaN   \n",
       "\n",
       "   Complaint ID  \n",
       "0       3515096  \n",
       "1       3564439  \n",
       "2       3633318  \n",
       "3       3594679  \n",
       "4       3611900  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfpb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Reviewed my credit report in XX/XX/XXXX and no...\n",
       "1    TransUnion has not properly investigated the i...\n",
       "2    XX/XX/2020 someone tried to steal my identity ...\n",
       "3    I paid the debt on XX/XX/XXXX. I disputed acco...\n",
       "4    A COLLECTION HAS BEEN REPORTED TO MY CREDIT RE...\n",
       "Name: Consumer complaint narrative, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfpb['Consumer complaint narrative'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is the **process of splitting text into words and sentences.** These chunks (words, sentences, etc.) are called **tokens**. One approach might be to try to do this use string methods like [str.split](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html). The problem with this is that using a separator like a \",\" or \".\" or \" \" may not work for some common situations. So instead, we'll use the [spaCy](https://spacy.io/) library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why tokenize?\n",
    "\n",
    "Electronic text is a linear sequence of symbols. Before any processing can be done, text needs to be segmented into linguistic units, and this process is called tokenization.\n",
    "\n",
    "We usually look at grammar and meaning at the level of words, related to each other within sentences, within each document. So if we're starting with raw text, we first need to split the text into sentences, and those sentences into words -- which we call \"tokens\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to tokenize\n",
    "\n",
    "#### Using String Methods\n",
    "\n",
    "##### Split Into Sentences\n",
    "\n",
    "You might imagine that the easiest way to identify sentences is to split the document at every period '.', and to split the sentences using white space to get the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewed my credit report in XX/XX/XXXX and noticed a lot of errors, inconsistent, and incorrect information\n",
      "\n",
      " Sent a letter to Equifax on XX/XX/XXXX via mail asking them for an investigation and to verify all the dates and amounts were correct and fix the incorrect reporting on my credit\n",
      "\n",
      " They did not respond at all so I sent another letter on XX/XX/XXXX via mail, again asking for an investigation and proof\n",
      "\n",
      " They still didnt respond to that letter so I sent a third letter on XX/XX/XXXX certified mail so I have proof that they signed for my letter\n",
      "\n",
      "\n",
      "\n",
      "Last week I received two letters from Equifax dated XX/XX/XXXX on the same day\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using the split function to create tokens\n",
    "text = cfpb['Consumer complaint narrative'][0]\n",
    "paragraph = text\n",
    "sentences = paragraph.split(\".\")\n",
    "for s in sentences[:5]:\n",
    "    print(s + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be ok, but what if someone said something like \"U.C. Berkeley charged me $50.11 by mistake.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n",
      "\n",
      "C\n",
      "\n",
      " Berkeley charged me $50\n",
      "\n",
      "11 by mistake\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_text = \"U.C. Berkeley charged me $50.11 by mistake.\"\n",
    "bad_sentences = bad_text.split(\".\")\n",
    "for s in bad_sentences[:5]:\n",
    "    print(s + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look too good! The one sentence was split into 4 separate sentences because \".\"'s are used for things other than ending a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split Into Tokens\n",
    "From here, we might split each sentence into tokens by splitting on white space in between words. Try filling in the code below to take the first sentence and split on white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reviewed',\n",
       " 'my',\n",
       " 'credit',\n",
       " 'report',\n",
       " 'in',\n",
       " 'XX/XX/XXXX',\n",
       " 'and',\n",
       " 'noticed',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'errors,',\n",
       " 'inconsistent,',\n",
       " 'and',\n",
       " 'incorrect',\n",
       " 'information']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = sentences[0]\n",
    "tokens = sentence.split(\" \")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Challenge 1: What was the problem with splitting on the white space? Are there any tokens that look a little strange?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: We may not want some words to have commas after them like \"errors,\" and \"inconsistent,\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to string methods, spaCy uses pre-trained language models to incorporate context. In this case, we'll load the [en_core_web_sm](https://spacy.io/models/en), which is one of spaCy's English language models. For instance, the end of a sentence (\".\") should mark a new token, but the string \"U.K.\" should not be separated at the \".\"'s. According to [spaCy's documentation](https://spacy.io/usage/spacy-101#annotations-token) it achieves this by taking the following steps:\n",
    "\n",
    "First, the raw text is split on whitespace characters, similar to text.split(' '). Then, the tokenizer processes the text from left to right. On each substring, it performs two checks:\n",
    "\n",
    "1. Does the substring match a tokenizer exception rule? For example, “don’t” does not contain whitespace, but should be split into two tokens, “do” and “n’t”, while “U.K.” should always remain one token.\n",
    "2. Can a prefix, suffix or infix be split off? For example punctuation like commas, periods, hyphens or quotes.\n",
    "\n",
    "If there’s a match, the rule is applied and the tokenizer continues its loop, starting with the newly split substrings. This way, spaCy can split complex, nested tokens like combinations of abbreviations and multiple punctuation marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try applying these methods to our CFPB data. The steps to do this are:\n",
    "\n",
    "1. Load the language model.\n",
    "2. Apply it to a piece of text and save it in an spaCy \"doc\" object.\n",
    "3. Extract each token from the doc object to a list.\n",
    "4. Display the tokens\n",
    "\n",
    "Check the documentation for help filling in these steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Tokenized words: ['Reviewed', 'my', 'credit', 'report', 'in', 'XX', '/', 'XX', '/', 'XXXX', 'and', 'noticed', 'a', 'lot', 'of', 'errors', ',', 'inconsistent', ',', 'and', 'incorrect', 'information', '.', 'Sent', 'a', 'letter', 'to', 'Equifax', 'on', 'XX', '/', 'XX', '/', 'XXXX', 'via', 'mail', 'asking', 'them', 'for', 'an', 'investigation', 'and', 'to', 'verify', 'all', 'the', 'dates', 'and', 'amounts', 'were', 'correct', 'and', 'fix', 'the', 'incorrect', 'reporting', 'on', 'my', 'credit', '.', 'They', 'did', 'not', 'respond', 'at', 'all', 'so', 'I', 'sent', 'another', 'letter', 'on', 'XX', '/', 'XX', '/', 'XXXX', 'via', 'mail', ',', 'again', 'asking', 'for', 'an', 'investigation', 'and', 'proof', '.', 'They', 'still', 'did', 'nt', 'respond', 'to', 'that', 'letter', 'so', 'I', 'sent', 'a', 'third', 'letter', 'on', 'XX', '/', 'XX', '/', 'XXXX', 'certified', 'mail', 'so', 'I', 'have', 'proof', 'that', 'they', 'signed', 'for', 'my', 'letter', '.', '\\\\r\\\\n\\\\r\\\\n', 'Last', 'week', 'I', 'received', 'two', 'letters', 'from', 'Equifax', 'dated', 'XX', '/', 'XX', '/', 'XXXX', 'on', 'the', 'same', 'day', '.', 'The', 'said', 'that', 'they', 'could', 'not', 'locate', 'my', 'credit', 'file', 'and', 'needed', 'me', 'to', 'send', 'proof', 'of', 'identification', 'and', 'address', '.', 'With', 'all', 'three', 'letters', 'I', 'sent', 'a', 'copy', 'of', 'my', 'Arizona', 'drivers', 'license', 'and', 'my', 'XXXX', 'direct', 'deposit', 'sub', 'as', 'my', 'proof', 'of', 'address', '.', 'The', 'second', 'letter', 'said', 'that', 'they', 'received', 'my', 'request', 'to', 'be', 'removed', 'from', 'the', 'promotions', 'list', 'and', 'that', 'it', 'was', 'added', 'to', 'my', 'credit', 'file', '.', 'How', 'did', 'they', 'find', 'my', 'file', 'to', 'add', 'the', 'restriction', 'if', 'they', 'could', 'nt', 'find', 'my', 'credit', 'file', 'in', 'regards', 'to', 'investigation', 'purposes', '?']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "doc = nlp(text)\n",
    "spacy_words = [token.text for token in doc]\n",
    "display(f\"Tokenized words: {spacy_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Stop Words and Punctuation\n",
    "\n",
    "We now have some tokens with just a few lines of code! There are a few additional steps that we might want to take. For example, we may want to remove punctuation and stop words. Punctuation oftentimes does not add substantive information to a piece of text, and stop words are common words that appear very frequently across texts. Removing this kind of information can help with downstream classification tasks by allowing an algorithm to focus on words that distinguish documents, rather than ones that appear frequently across them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at stop words. We can start by importing a collection of stop words from spaCy by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-804e8575607c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_words\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSTOP_WORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at some common stop words from this collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['somehow',\n",
       " 'hereby',\n",
       " 'just',\n",
       " 'side',\n",
       " 'sometimes',\n",
       " 'hundred',\n",
       " 'below',\n",
       " 'throughout',\n",
       " 'show',\n",
       " 'my']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(STOP_WORDS)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing punctuation and stop words is not a hard and fast rule - there may be situations where you want to keep them. In most applications, they add noise to downstream tasks, but always be mindful of your particular application when making decisions. Now that we have some tokenization tools, let's put them all together in a function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Challenge 2: Write a function that takes a piece of text as an argument, and returns a list of tokens without punctuation or stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_reduced = []\n",
    "\n",
    "def rem_punc_stop(text):\n",
    "    stop_words = STOP_WORDS\n",
    "    punc = set(punctuation)\n",
    "    \n",
    "    punc_free = \"\".join([ch for ch in text if ch not in punc])\n",
    "    \n",
    "    doc = nlp(punc_free)\n",
    "    \n",
    "    spacy_words = [token.text for token in doc]\n",
    "    \n",
    "    no_punc = [word for word in spacy_words if word not in stop_words]\n",
    "    \n",
    "    return no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reviewed', 'credit', 'report', 'XXXXXXXX', 'noticed']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_reduced = rem_punc_stop(text)\n",
    "tokens_reduced[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy also contains a number of methods for things like entity recognition. For instance, we could run the following code to check various entities. Notice that this process isn't perfect, spaCy still thinks \"XX/XX/XXXX\" is an organization or product even though we know this is a redacted date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XX/XX/XXXX - ORG - Companies, agencies, institutions, etc.\n",
      "Equifax - PERSON - People, including fictional\n",
      "XX/XX/XXXX - ORG - Companies, agencies, institutions, etc.\n",
      "XX/XX/XXXX - ORG - Companies, agencies, institutions, etc.\n",
      "third - ORDINAL - \"first\", \"second\", etc.\n",
      "XX/XX/XXXX - ORG - Companies, agencies, institutions, etc.\n",
      "Last week - DATE - Absolute or relative dates or periods\n",
      "two - CARDINAL - Numerals that do not fall under another type\n",
      "Equifax - ORG - Companies, agencies, institutions, etc.\n",
      "XX/XX/XXXX - ORG - Companies, agencies, institutions, etc.\n",
      "three - CARDINAL - Numerals that do not fall under another type\n",
      "Arizona - GPE - Countries, cities, states\n",
      "XXXX - ORG - Companies, agencies, institutions, etc.\n",
      "second - ORDINAL - \"first\", \"second\", etc.\n"
     ]
    }
   ],
   "source": [
    "for entity in nlp(text).ents:\n",
    "    print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another preprocessing step we might take is reducing words down to their lemmas. Lemmatization reduces a word to its root word, while making sure the word still belongs to the language. This is in contrast to stemming, which reduces the word down to its root even if that root is not a valid word. Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute compute\n",
      "computer computer\n",
      "computed compute\n",
      "computing compute\n"
     ]
    }
   ],
   "source": [
    "for word in nlp(u'compute computer computed computing'):\n",
    "    print(word.text,  word.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming these words would all result in the root \"comput\" but lemmatization converted these words to their shortest variant. Again, you may choose to stem or lemmatize depending on your specific application.\n",
    "\n",
    "##### Challenge 3: Lemmatize the first consumer complaint narrative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewed reviewed\n",
      "my -PRON-\n",
      "credit credit\n",
      "report report\n",
      "in in\n",
      "XX XX\n",
      "/ /\n",
      "XX XX\n",
      "/ /\n",
      "XXXX XXXX\n",
      "and and\n",
      "noticed notice\n",
      "a a\n",
      "lot lot\n",
      "of of\n",
      "errors error\n",
      ", ,\n",
      "inconsistent inconsistent\n",
      ", ,\n",
      "and and\n",
      "incorrect incorrect\n",
      "information information\n",
      ". .\n",
      "Sent send\n",
      "a a\n",
      "letter letter\n",
      "to to\n",
      "Equifax Equifax\n",
      "on on\n",
      "XX XX\n",
      "/ /\n",
      "XX XX\n",
      "/ /\n",
      "XXXX xxxx\n",
      "via via\n",
      "mail mail\n",
      "asking ask\n",
      "them -PRON-\n",
      "for for\n",
      "an an\n",
      "investigation investigation\n",
      "and and\n",
      "to to\n",
      "verify verify\n",
      "all all\n",
      "the the\n",
      "dates date\n",
      "and and\n",
      "amounts amount\n",
      "were be\n",
      "correct correct\n",
      "and and\n",
      "fix fix\n",
      "the the\n",
      "incorrect incorrect\n",
      "reporting report\n",
      "on on\n",
      "my -PRON-\n",
      "credit credit\n",
      ". .\n",
      "They -PRON-\n",
      "did do\n",
      "not not\n",
      "respond respond\n",
      "at at\n",
      "all all\n",
      "so so\n",
      "I -PRON-\n",
      "sent send\n",
      "another another\n",
      "letter letter\n",
      "on on\n",
      "XX XX\n",
      "/ /\n",
      "XX XX\n",
      "/ /\n",
      "XXXX xxxx\n",
      "via via\n",
      "mail mail\n",
      ", ,\n",
      "again again\n",
      "asking ask\n",
      "for for\n",
      "an an\n",
      "investigation investigation\n",
      "and and\n",
      "proof proof\n",
      ". .\n",
      "They -PRON-\n",
      "still still\n",
      "did do\n",
      "nt not\n",
      "respond respond\n",
      "to to\n",
      "that that\n",
      "letter letter\n",
      "so so\n",
      "I -PRON-\n",
      "sent send\n",
      "a a\n",
      "third third\n",
      "letter letter\n",
      "on on\n",
      "XX XX\n",
      "/ /\n",
      "XX XX\n",
      "/ /\n",
      "XXXX XXXX\n",
      "certified certify\n",
      "mail mail\n",
      "so so\n",
      "I -PRON-\n",
      "have have\n",
      "proof proof\n",
      "that that\n",
      "they -PRON-\n",
      "signed sign\n",
      "for for\n",
      "my -PRON-\n",
      "letter letter\n",
      ". .\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Last last\n",
      "week week\n",
      "I -PRON-\n",
      "received receive\n",
      "two two\n",
      "letters letter\n",
      "from from\n",
      "Equifax Equifax\n",
      "dated date\n",
      "XX XX\n",
      "/ /\n",
      "XX XX\n",
      "/ /\n",
      "XXXX xxxx\n",
      "on on\n",
      "the the\n",
      "same same\n",
      "day day\n",
      ". .\n",
      "The the\n",
      "said say\n",
      "that that\n",
      "they -PRON-\n",
      "could could\n",
      "not not\n",
      "locate locate\n",
      "my -PRON-\n",
      "credit credit\n",
      "file file\n",
      "and and\n",
      "needed need\n",
      "me -PRON-\n",
      "to to\n",
      "send send\n",
      "proof proof\n",
      "of of\n",
      "identification identification\n",
      "and and\n",
      "address address\n",
      ". .\n",
      "With with\n",
      "all all\n",
      "three three\n",
      "letters letter\n",
      "I -PRON-\n",
      "sent send\n",
      "a a\n",
      "copy copy\n",
      "of of\n",
      "my -PRON-\n",
      "Arizona Arizona\n",
      "drivers driver\n",
      "license license\n",
      "and and\n",
      "my -PRON-\n",
      "XXXX xxxx\n",
      "direct direct\n",
      "deposit deposit\n",
      "sub sub\n",
      "as as\n",
      "my -PRON-\n",
      "proof proof\n",
      "of of\n",
      "address address\n",
      ". .\n",
      "The the\n",
      "second second\n",
      "letter letter\n",
      "said say\n",
      "that that\n",
      "they -PRON-\n",
      "received receive\n",
      "my -PRON-\n",
      "request request\n",
      "to to\n",
      "be be\n",
      "removed remove\n",
      "from from\n",
      "the the\n",
      "promotions promotion\n",
      "list list\n",
      "and and\n",
      "that that\n",
      "it -PRON-\n",
      "was be\n",
      "added add\n",
      "to to\n",
      "my -PRON-\n",
      "credit credit\n",
      "file file\n",
      ". .\n",
      "How how\n",
      "did do\n",
      "they -PRON-\n",
      "find find\n",
      "my -PRON-\n",
      "file file\n",
      "to to\n",
      "add add\n",
      "the the\n",
      "restriction restriction\n",
      "if if\n",
      "they -PRON-\n",
      "could could\n",
      "nt not\n",
      "find find\n",
      "my -PRON-\n",
      "credit credit\n",
      "file file\n",
      "in in\n",
      "regards regard\n",
      "to to\n",
      "investigation investigation\n",
      "purposes purpose\n",
      "? ?\n"
     ]
    }
   ],
   "source": [
    "for word in nlp(text):\n",
    "    print(word.text,  word.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also want to chunk more than one word together. One way to do this might be to group nounds together. \n",
    "\n",
    "**Challenge 4: Trying using the [`noun_chunks`](https://spacy.io/api/doc#noun_chunks) method to chunk nouns in the first complaint.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my credit report\n",
      "XX/XX/XXXX\n",
      "a lot\n",
      "errors\n",
      "incorrect information\n",
      "a letter\n",
      "Equifax\n",
      "XX/XX/XXXX\n",
      "mail\n",
      "them\n",
      "an investigation\n",
      "all the dates\n",
      "amounts\n",
      "my credit\n",
      "They\n",
      "I\n",
      "another letter\n",
      "XX/XX/XXXX\n",
      "mail\n",
      "an investigation\n",
      "proof\n",
      "They\n",
      "that letter\n",
      "I\n",
      "a third letter\n",
      "XX/XX/XXXX certified mail\n",
      "I\n",
      "proof\n",
      "they\n",
      "my letter\n",
      "I\n",
      "two letters\n",
      "Equifax\n",
      "dated XX/XX/XXXX\n",
      "the same day\n",
      "they\n",
      "my credit file\n",
      "me\n",
      "proof\n",
      "identification\n",
      "address\n",
      "all three letters\n",
      "I\n",
      "a copy\n",
      "my Arizona drivers license\n",
      "my XXXX direct deposit sub\n",
      "my proof\n",
      "address\n",
      "The second letter\n",
      "they\n",
      "my request\n",
      "the promotions list\n",
      "it\n",
      "my credit file\n",
      "they\n",
      "my file\n",
      "the restriction\n",
      "they\n",
      "my credit file\n",
      "regards\n",
      "investigation purposes\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for np in doc.noun_chunks:\n",
    "    print(np.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have covered some the basics of text preprocessing, we are ready to start getting our data in a format for feeding it into machine learning algorithms. There are many options for converting raw text to features in a supervised machine learning problem. The most basic of these is the \"bag of words\" approach. Bag of words essentially counts the number of times each word appears in a corpus, and these counts become features.\n",
    "\n",
    "To illustrate, first let's import the CounterVectorizer method from sklearn. Once we do that, let's use our tokenizer function that we wrote earlier to initialize the CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = rem_punc_stop, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we create a CountVectorizer object, we can then transform a list of texts with the \"fit_transform\" method. This will return a sparse matrix with the counts. We can densify the matrix with the \".todense()\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix = bow_vector.fit_transform(cfpb['Consumer complaint narrative'][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0,  1,  0,  0,  0,  1,  1,  2,  1,  1,  2,  0,  0,  1,  0,  0,\n",
       "          0,  1,  1,  5,  1,  1,  1,  0,  1,  1,  0,  0,  0,  1,  2,  1,\n",
       "          4,  0,  2,  1,  0,  0,  1,  0,  1,  2,  1,  0,  0,  3,  0,  6,\n",
       "          2,  1,  1,  1,  1,  3,  1,  1,  2,  0,  0,  0,  0,  1,  4,  0,\n",
       "          1,  0,  2,  0,  1,  0,  1,  1,  0,  1,  1,  0,  2,  1,  0,  1,\n",
       "          2,  1,  1,  4,  0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  0,  1,\n",
       "          1,  1,  0,  0,  5],\n",
       "        [ 0,  1,  2,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  1,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1,\n",
       "          0,  0,  0,  0,  0,  0,  1,  1,  0,  0,  0,  1,  0,  0,  1,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  0,  7,  0,\n",
       "          0, 26,  7,  0,  0],\n",
       "        [ 1,  0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,\n",
       "          1,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  1,  3,  0,  1,  0,  0,  0,  3,  0,  0,  0,  1,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
       "          0,  1,  0,  1,  0,  2,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  1,  1,  0,  0,  1,  0,  2,  1,  0,  0,\n",
       "          0, 21,  0,  1,  2],\n",
       "        [ 0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,\n",
       "          0,  0,  0,  1,  0,  0,  0,  1,  0,  0,  1,  1,  1,  0,  0,  0,\n",
       "          0,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
       "          0,  1,  0,  0,  2],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "          0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  1,  1,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\r\\n',\n",
       " '\\r\\n\\r\\n',\n",
       " ' ',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'add',\n",
       " 'added',\n",
       " 'address',\n",
       " 'amounts',\n",
       " 'arizona']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = bow_vector.get_feature_names()\n",
    "feature_names[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extension of bag-of-words is the term frequency-inverse document frequency approach. Whereas bag-of-words counts the number of words in the document. tf-idf takes this quanity and divides it by how frequently the word shows up across the corpus. In doing so, the tf-idf score downweights words that are common in the corpus and thus would not aid with classification.\n",
    "\n",
    "**Challenge 5: Using the code from the \"Bag of Words\" section as a template, write code to get the tf-idf matrix for the CFPB data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = rem_punc_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = tfidf_vector.fit_transform(cfpb['Consumer complaint narrative'][0:5])\n",
    "feature_names = tfidf_vector.get_feature_names()\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.0591843 , 0.        , 0.        , 0.        ,\n",
       "         0.07335741, 0.07335741, 0.14671482, 0.07335741, 0.07335741,\n",
       "         0.14671482, 0.        , 0.        , 0.07335741, 0.        ,\n",
       "         0.        , 0.        , 0.07335741, 0.07335741, 0.20664143,\n",
       "         0.07335741, 0.07335741, 0.07335741, 0.        , 0.07335741,\n",
       "         0.07335741, 0.        , 0.        , 0.        , 0.07335741,\n",
       "         0.14671482, 0.07335741, 0.29342964, 0.        , 0.14671482,\n",
       "         0.07335741, 0.        , 0.        , 0.07335741, 0.        ,\n",
       "         0.07335741, 0.11836859, 0.07335741, 0.        , 0.        ,\n",
       "         0.22007223, 0.        , 0.35510578, 0.14671482, 0.07335741,\n",
       "         0.07335741, 0.07335741, 0.07335741, 0.22007223, 0.07335741,\n",
       "         0.07335741, 0.14671482, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.07335741, 0.29342964, 0.        , 0.07335741,\n",
       "         0.        , 0.14671482, 0.        , 0.07335741, 0.        ,\n",
       "         0.04912831, 0.0349552 , 0.        , 0.07335741, 0.07335741,\n",
       "         0.        , 0.14671482, 0.07335741, 0.        , 0.07335741,\n",
       "         0.14671482, 0.07335741, 0.07335741, 0.29342964, 0.        ,\n",
       "         0.07335741, 0.        , 0.        , 0.07335741, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.07335741, 0.07335741, 0.04132829, 0.        , 0.        ,\n",
       "         0.24564156],\n",
       "        [0.        , 0.04474299, 0.08948598, 0.        , 0.05545779,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.05545779,\n",
       "         0.        , 0.05545779, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.05545779,\n",
       "         0.        , 0.        , 0.        , 0.05545779, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03714073, 0.02642593, 0.        , 0.        , 0.        ,\n",
       "         0.05545779, 0.        , 0.        , 0.05545779, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.05545779, 0.04474299, 0.        , 0.3882045 ,\n",
       "         0.        , 0.        , 0.81234268, 0.3882045 , 0.        ,\n",
       "         0.        ],\n",
       "        [0.07209713, 0.        , 0.23267005, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.07209713, 0.        , 0.        ,\n",
       "         0.        , 0.07209713, 0.        , 0.        , 0.08123653,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.07209713, 0.21629139, 0.        , 0.07209713,\n",
       "         0.        , 0.        , 0.        , 0.21629139, 0.        ,\n",
       "         0.        , 0.        , 0.05816751, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.07209713, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.07209713, 0.        , 0.07209713, 0.        , 0.14419426,\n",
       "         0.04828429, 0.03435467, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.07209713, 0.07209713, 0.        , 0.        ,\n",
       "         0.07209713, 0.        , 0.11633502, 0.07209713, 0.        ,\n",
       "         0.        , 0.        , 0.85298359, 0.        , 0.07209713,\n",
       "         0.09656858],\n",
       "        [0.        , 0.        , 0.        , 0.45897643, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.22948821, 0.        , 0.        , 0.22948821,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.12928966,\n",
       "         0.        , 0.        , 0.        , 0.22948821, 0.        ,\n",
       "         0.        , 0.22948821, 0.22948821, 0.22948821, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.22948821, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.18514965, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.22948821, 0.        ,\n",
       "         0.22948821, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.21870473, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.22948821,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.22948821,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.12928966, 0.        , 0.        ,\n",
       "         0.30738186],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.62690599, 0.        , 0.        , 0.        , 0.3531879 ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.29872406, 0.62690599, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have featurized our text, we are ready to make a prediction! Does the text of our consumer complaints predict whether or not they get a timely response?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge 6: Transform the text of the consumer complaint narrative into a tf-idf matrix, and use it to predict the \"Timely response?\" column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfpb = cfpb[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training, Validation, Test Sets\n",
    "\n",
    "# X\n",
    "X = cfpb['Consumer complaint narrative']\n",
    "tf = TfidfVectorizer(tokenizer = rem_punc_stop)\n",
    "\n",
    "tfidf_matrix =  tf.fit_transform(X)\n",
    "\n",
    "#y\n",
    "\n",
    "y = cfpb['Timely response?']\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, y,\n",
    "                                                   train_size = .80,\n",
    "                                                   test_size = .20)\n",
    "\n",
    "# Train/Validation Split\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train,\n",
    "                                                           train_size = .75,\n",
    "                                                           test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb_model = nb.fit(X_train, y_train)\n",
    "\n",
    "nb_pred = nb_model.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  10],\n",
       "       [  0, 990]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean(nb_pred == y_validate))\n",
    "\n",
    "nb_cf_matrix = confusion_matrix(y_validate, nb_pred)\n",
    "nb_cf_matrix\n",
    "#Let's plot the confusion matrix! Use the following code from the \"seaborn\" package to make a heatmap out of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_df_cm = pd.DataFrame(nb_cf_matrix, range(2),\n",
    "                  range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1\n",
       "0  0   10\n",
       "1  0  990"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_df_cm = nb_df_cm.rename(index=str, columns={0: \"no\", 1: \"yes\"})\n",
    "nb_df_cm.index = [\"no\", \"yes\"]\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(nb_df_cm, \n",
    "           annot=True,\n",
    "           annot_kws={\"size\": 16})\n",
    "\n",
    "plt.title(\"Naive Bayes Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
