{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning and Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wNqj6s9msZga"
      ],
      "authorship_tag": "ABX9TyMUrxXVGfaA5zP7fV2yVW4Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c8a86d4a4f00485ab53dd4f186dd7923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4adbee71dccb44788b2e8a38086bd740",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a4dbf5952ea47b29525d67e31e0f6d8",
              "IPY_MODEL_67542e1598204918863250f7ccb19f45",
              "IPY_MODEL_e52415d9a93b40809ce72af204017356"
            ]
          }
        },
        "4adbee71dccb44788b2e8a38086bd740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a4dbf5952ea47b29525d67e31e0f6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81b6c6649c3348fd972d6e922f447b7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a3dd8bb6d254dbe9ff078e01d69af54"
          }
        },
        "67542e1598204918863250f7ccb19f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_192b1683f74244609ab990f86c4d50a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 629,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 629,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_974637d371c5458c86c8c817ed7d546c"
          }
        },
        "e52415d9a93b40809ce72af204017356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93025786d1db4b71bd839a32152ff0ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 629/629 [00:00&lt;00:00, 17.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e3ce28b50f44f7584dd1f9bdb86e63b"
          }
        },
        "81b6c6649c3348fd972d6e922f447b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a3dd8bb6d254dbe9ff078e01d69af54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "192b1683f74244609ab990f86c4d50a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "974637d371c5458c86c8c817ed7d546c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93025786d1db4b71bd839a32152ff0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e3ce28b50f44f7584dd1f9bdb86e63b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ba74fea58594764b917cca9898f6789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da3afbc514df48b4ab32a3762de4b11e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_099a63f668bb41b3b696040101a743c2",
              "IPY_MODEL_4c22aece7bc34948bb6fa7dd7211c489",
              "IPY_MODEL_32d57eee7e0a4328ab5be9fa45b5c466"
            ]
          }
        },
        "da3afbc514df48b4ab32a3762de4b11e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "099a63f668bb41b3b696040101a743c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_834c835a023049e797c97088f80620c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_764762ff43a544f0a60ce87cbbb96f98"
          }
        },
        "4c22aece7bc34948bb6fa7dd7211c489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ddac78a3c1f84da1b1fce8f86143328c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267844284,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267844284,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_089f32eb33d64f9eba137033bbb1c447"
          }
        },
        "32d57eee7e0a4328ab5be9fa45b5c466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb4448827a0d452a876389c7c9963956",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 255M/255M [00:06&lt;00:00, 49.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6aac0ac6c95475aa852b980ca4936cd"
          }
        },
        "834c835a023049e797c97088f80620c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "764762ff43a544f0a60ce87cbbb96f98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddac78a3c1f84da1b1fce8f86143328c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "089f32eb33d64f9eba137033bbb1c447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb4448827a0d452a876389c7c9963956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6aac0ac6c95475aa852b980ca4936cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "778f78a61330498fa51d1a9c20c9f3ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e9d7b29295a94a95ae9aa711386c6a1c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_33e581c215384e51be58035219329b91",
              "IPY_MODEL_647eedfeb3134499b524b66fb06e1587",
              "IPY_MODEL_2e7f2e6d27e242a2a089f686ffab55a5"
            ]
          }
        },
        "e9d7b29295a94a95ae9aa711386c6a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33e581c215384e51be58035219329b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d461230c7a634df786353d3595b337db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4ca43dac4f04b8cb7b1be631b3a919b"
          }
        },
        "647eedfeb3134499b524b66fb06e1587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1108d5c375234c7facd9d19481be8d2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 48,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 48,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e920e80a5be04092b7744c30aa49afeb"
          }
        },
        "2e7f2e6d27e242a2a089f686ffab55a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d5efd77976e4b70ae3984ca5157f1d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.48kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8e8cfb841594d6fa734215119e87016"
          }
        },
        "d461230c7a634df786353d3595b337db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4ca43dac4f04b8cb7b1be631b3a919b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1108d5c375234c7facd9d19481be8d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e920e80a5be04092b7744c30aa49afeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d5efd77976e4b70ae3984ca5157f1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8e8cfb841594d6fa734215119e87016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79b5f56a61f3422880aa72c012ee1a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eda808930d05426ab516fe5c6766cc83",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0319b3fcb679423fb68966c2e17d8a55",
              "IPY_MODEL_25b5b10ddb8749efb9dddca1e18a0f23",
              "IPY_MODEL_cb1dcb6aff094b0ea40a15c0472ce5d9"
            ]
          }
        },
        "eda808930d05426ab516fe5c6766cc83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0319b3fcb679423fb68966c2e17d8a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50991ea0da224d6182d1e4dbfc23a2e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a9f7d048b33408f97aa23614c3936a8"
          }
        },
        "25b5b10ddb8749efb9dddca1e18a0f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ca9a6865dbf04b1b9f73ab7436c5623a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9329b12596734c87b6d5b381ad93c366"
          }
        },
        "cb1dcb6aff094b0ea40a15c0472ce5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_67f0c531d5754addac406e02a4c76e11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 1.84MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_087b592f2da34d32832b74236b652f5b"
          }
        },
        "50991ea0da224d6182d1e4dbfc23a2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a9f7d048b33408f97aa23614c3936a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca9a6865dbf04b1b9f73ab7436c5623a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9329b12596734c87b6d5b381ad93c366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67f0c531d5754addac406e02a4c76e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "087b592f2da34d32832b74236b652f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlab-berkeley/Computational-Social-Science-Training-Program/blob/master/Deep_Learning_and_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GPU, Deep Learning, and Tensorflow**\n"
      ],
      "metadata": {
        "id": "0DrTKxZ1hCS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will introduce you to the fundamentals of Tensorflow and explore techniques for deep learning with text data. Key concepts covered in this notebook include:\n",
        "\n",
        "1. Google Colab and GPUs\n",
        "2. Tensors and basic tensor operations\n",
        "3. Use tensorflow/keras to adapt and tune neural nets\n",
        "4. Existing resources to help analyze language data\n",
        "\n",
        "\n",
        "With these basic building blocks, you will be equipped to explore and implement deep learning algorithms for your own project. "
      ],
      "metadata": {
        "id": "XHoISf71wzH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wNqj6s9msZga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "\n",
        "- Set up a Google Colab notebook\n",
        "- Create, delete, run, and edit cells\n",
        "- Cover variable, notebook and package management"
      ],
      "metadata": {
        "id": "gNovoJcyugcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducing Google Colab\n",
        "\n",
        "\n",
        "Google Colab is a platform for cloud-based computation and coding. It can be thought of as similar to a jupyter notebook, where individual cells can be executed with code inside. It doesn't require local installation on your computer and can be shared and edited by multiple people at the same time. However the colab notebook requires you to be connected to the internet, while in comparison jupyter notebooks can be run on your machine offline. Google Colab notebooks are in the .ipynb format, and can be saved and opened either directly or via Google Drive. \n",
        "\n"
      ],
      "metadata": {
        "id": "L_zANHRDhplZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basic Operations\n",
        "\n",
        "Google Colab has several features that help organize code and long notebooks. A few key concept to know to use this notebook effectively are:\n",
        "\n",
        "- Use the Insert tab in the upper bar, or press the +Code/+Text buttons in the top left of the window.\n",
        "\n",
        "- ctrl/cmd +alt +n opens a scratch cell. This is a place to test code without needing to edit the main notebook.\n",
        "\n",
        "- Text cells can be edited and formatting with the buttons at the top of the cell.\n",
        "\n",
        "- The buttons at the top right of the cell give you options to move, modify and delete the cell. \n",
        "\n",
        "- You can run code with shift+enter, or by clicking the top left of the box.\n",
        "\n",
        "- For more commands, use ctl+shift+p and select the desired command from the command palette\n",
        "\n",
        "An example code cell is below:"
      ],
      "metadata": {
        "id": "oqx972vJvdVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Welcome to Google Colab\")\n",
        "x=12+78"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhl6KsHCrLP-",
        "outputId": "d096129e-fa85-426a-f8a9-268364ea2d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Google Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The buttons on the left panel help manage the notebook (search, table of contents, files). This is important for organizing your code and navigating long notebooks.\n",
        "\n"
      ],
      "metadata": {
        "id": "pT9L_Th9sPrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package Management\n",
        "\n",
        "Like Anaconda, Google Colab comes with many packages already available, and you can also install local packages using pip. Use the following lines of code in order to see which packages you have and which ones you need to install. Because this runs on the cloud, I suggest checking the packages here to confirm that you have the right ones for your project. \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "#check which packages you have available (listed alphabetically). The version numbers are also avaliable which can be useful in determining issues with coding between computers.\n",
        "!pip list\n",
        "\n",
        "#install a new package\n",
        "!pip install numpy \n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<List of packages that we will use in this tutorial>"
      ],
      "metadata": {
        "id": "VR9JpuTHcmVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell are the packages that you will need to complete this notebook:"
      ],
      "metadata": {
        "id": "fQ3GQZB7bo6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages for deep learning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "Qey74xT0boGX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customization\n",
        "\n",
        "Finally, there are several settings that you can customize if you so choose. These can be found under Tools -> Settings, where you can change the font size, background, and other aesthetic settings of the notebook to suit you. \n",
        "\n",
        "In addition, in Tools -> Keyboard shortcuts you can view and adapt shortcuts to your preferences as well.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pi2ikVCaoNct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "Try out the following exercises to get comfortable with the new interface:\n",
        "\n",
        "1) Open the editor settings (Tools-> Settings->Editor) and select \"Show line numbers\". Now your cells will have line numbers next to them, which we can refer to when discussing code during this workshop.\n",
        "\n",
        "2) Make a new code cell below and save the product of 60 and 72 to a new variable. Then check the value of the variable in the variable tab to the left.\n",
        "\n",
        "3) How many sections (main headers) are there in this notebook? Navigate to the Introduction to Tensors section. Collapse that section.\n",
        "\n",
        "4) How many times does 'variable' appear in this notebook? (hint, use the search feature on the left)\n",
        "\n",
        "5) The cell below contains code, but is in a text format. Use the Command Palette (ctrl+shift+p) and use the appropriate command to change the cell type."
      ],
      "metadata": {
        "id": "EHrAjcLHsYC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "print(\"Turn me into a code cell\")"
      ],
      "metadata": {
        "id": "2DWqUetbmeoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#solutions\n",
        "#1) follow the directions in the question\n",
        "#2) \n",
        "new = 60*72\n",
        "#3) 9 sections\n",
        "#4) 5 times\n",
        "#5) ctrl + shift + p --> \"convert to a code cell\"\n",
        "print(\"Turn me into a code cell\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2iLcnJj1-Ng",
        "outputId": "caa8cc42-0973-43e5-ac3a-cc0e8edb4962"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turn me into a code cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to GPU"
      ],
      "metadata": {
        "id": "A58nCiMsshpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "- Understand the benefits of GPUs\n",
        "- Set up GPU for Google Colab\n",
        "- Compare performance on tasks vs CPU"
      ],
      "metadata": {
        "id": "L1AkXBaoujUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you've found in your previous workshops, some models take a significant amount of time to run. Models may also exceed the capacity of the local computer's processing power. This will either result in code that never finished running, or an error message indicating that the code has timed out without completing. \n",
        "\n",
        "To counteract this issue, TPU/GPU are parallel processing units that greatly speed up models. This can make some models that are otherwse impossible to train possible (Think minutes rather than hours)\n",
        "\n",
        "TPU is made specifically for tensorflow architecture, and speeds it up even more than GPUs.\n",
        "\n",
        "## GPU Access\n",
        "Oftentimes you need to pay for cloud services and access to GPUs, but one advantage of Colab is that it has free access to a certain amount of GPU/TPU units. This access is somewhat limited, but should be more than enough for what we are using it for today. We will discuss limitations and further options for long-term use in a later section of the workshop.\n",
        "\n",
        "\n",
        "Additional resource: https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=sXnDmXR7RDr2"
      ],
      "metadata": {
        "id": "xp2UXU5HHTSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The notebook will automatically choose which device (read: GPU vs CPU) to run the code on, but if you want to make sure that something is being run on a certain device, you can select a specific device as in the snippet below. \n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "with tf.device(device_name):\n",
        "  #put task here\n",
        "  #return output\n",
        "```\n",
        "\n",
        "For now, we will trust the notebook's/ Tensorflow's allocation of computing power.\n",
        "\n"
      ],
      "metadata": {
        "id": "co9jxID0Utsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "1) Run the following lines of code to test how fast your computer can do a task. Report the results\n"
      ],
      "metadata": {
        "id": "F9xyYBVVRZlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "print(timeit.timeit('[x**2 for x in range(10)]'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqgQQ2a1SBDj",
        "outputId": "a40d1c72-1ba9-427c-9a2a-743ced130c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9254725389999976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)  Change the settings to use GPU:  Edit --> Notebook Settings --> Hardware Accelerator --> GPU\n",
        ". Run the code below to make sure GPU is enabled."
      ],
      "metadata": {
        "id": "yx9qArhdR-31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#run this code to check that you have the GPU enabled\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow0GhY3ANepm",
        "outputId": "e8c20839-2758-45fa-b506-71d5fedaf309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Re-run the same timing task and report your results. How much of a difference is there in timing?"
      ],
      "metadata": {
        "id": "L6kl-9FvVbBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "print(timeit.timeit('[x**2 for x in range(10)]'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9ADVC5SVabz",
        "outputId": "559c8a0f-48de-4f8d-be03-5ab55c46f185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9785137800000143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Change the task to be more complex (= longer to run), and compare the GPU vs no GPU time."
      ],
      "metadata": {
        "id": "swoIbMog3Lqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we run more complex tasks, the efficiency of GPUs becomes more and more of a difference. If you are curious, you can compare the timing of the tasks in this notebook with GPU/TPU/CPU and note the difference. Even though in this notebook we are working with fairly small dataset and task, these differences will be important at larger scale."
      ],
      "metadata": {
        "id": "8GvtUiHVV6IO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manpulating Tensors"
      ],
      "metadata": {
        "id": "Q_hXKH0wu5XL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "- Understand the tensor data type\n",
        "- Index, reshape, and slice tensors"
      ],
      "metadata": {
        "id": "8L9b-y83u6bR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Neural Networks section of the course, you were introduced to Multilayer Perceptrons as a basic building block of neural networks. You were also introduced to using Keras to build a neural network for digit recognition. In this section we will further explore the powerful Keras/Tensorflow framework for neural networks.\n",
        "\n",
        "Tensors are the key data structure in Tensorflow. They are simlar to numpy arrays, but can be used with GPUs, which is necessary for large calculations. Tensors have one or more dimensions, are rectangular, and are immutable. Every entry in a tensor must have the same datatype (usually float).\n",
        "\n",
        "A 3-dimensional tensor can be visually represented in a few different ways. It can be represented as a mxnxp dimensional block:\n",
        "\n",
        "\n",
        "![3-axis_block.png](https://drive.google.com//uc?id=1ZQIeFD5zm-Nnh28bfgooXnb0AqlaWNzB)\n",
        "\n",
        "\n",
        "Or the block can be flattened out to three mxn dimensional arrays:\n",
        "\n",
        "![3-axis_numpy.png](https://drive.google.com//uc?id=1TyHhSZ66fJcFYGGkHrnmI3ZlNZ7-5RJW)\n",
        "\n",
        "\n",
        "The *shape* of this tensor is 5x3x2 and the *size* is 30, since there are 30 total units in the tensor. Although they are harder to visualize, tensors can have many dimensions.\n",
        "\n",
        "\n",
        "In Tensorflow, since we are handling every step of the process, tracking the dimensions, shapes, sizes of the tensors is an essential skill for working with this code. \n",
        "\n",
        "Images from: https://www.tensorflow.org/guide/tensor"
      ],
      "metadata": {
        "id": "FGfJ5yBMaDa0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Operations\n",
        "\n",
        "Just like manipulating dataframes or arrays, manipulating tensors is an important skill. There are some basic tensor operations that it is useful to be aware of for manipulating tensors. We will explore these with the same example tensor from above."
      ],
      "metadata": {
        "id": "oHzdlBc3dtqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a tensor from an array\n",
        "\n",
        "Tensors are similar to numpy array and tensorflow will automatically convert an array to a tensor when using tensorflow operations. Similarly, .numpy() can convert a tensor to an array.\n",
        "\n",
        "\n",
        "More commonly, you will most likely be using methods that process data and output a tensor that you can then work with, and most conversions to tensors will be handled automatically within those methods. "
      ],
      "metadata": {
        "id": "Y6f-T3hs4GR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data=np.array([[[0,1,2,3,4],[5,6,7,8,9]],\n",
        "      [[10,11,12,13,14],[15,16,17,18,19]],\n",
        "      [[20,21,22,23,24],[25,26,27,28,29]]])\n",
        "print('The original data type is:',type(data))\n",
        "sample_tensor=tf.concat(data,2)\n",
        "print('The new data type is:',type(sample_tensor))\n",
        "print(sample_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GUXRFkAe59o",
        "outputId": "a7e35604-9fcd-4aaa-b8b2-c7ac229c2918"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original data type is: <class 'numpy.ndarray'>\n",
            "The new data type is: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Indexing\n",
        "Indexing allows you to select subsections of the tensor. This is a very useful skill, but can get confusing with high dimensions. You can select a single number, or range of numbers in the tensor by specifying the position of the number in each dimension."
      ],
      "metadata": {
        "id": "Rhd9K7eQU8AE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get a single number\n",
        "sample_tensor[0,0,0]\n",
        "print(sample_tensor[0,0,0].numpy()) #.numpy() converts it to an array to print\n",
        "\n",
        "#get a range of values\n",
        "print(sample_tensor[0:2,1:2,:3].numpy()) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gLiSuEke8RK",
        "outputId": "b7c52cb4-05fc-4c7c-9a0e-36eb0c75e511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[[[ 5  6  7]]\n",
            "\n",
            " [[15 16 17]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Slicing"
      ],
      "metadata": {
        "id": "_a87fUneCsqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another important skill is to take a slice of a tensor. This is a subset of the tensor that is of a smaller dimension than the original tensor. Compare the following slices to the image above. Which part of the tensor is being sliced? What is the shape of each of the slices?\n",
        "\n"
      ],
      "metadata": {
        "id": "E8YhTpmYV7YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#index a slice\n",
        "print(sample_tensor[0,:,:].numpy())\n",
        "\n",
        "print(sample_tensor[:,0,:].numpy())\n",
        "\n",
        "print(sample_tensor[:,:,0].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrRY61zKV7-C",
        "outputId": "b31a5bea-cd63-472a-faa8-f64c7f47a5b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 2 3 4]\n",
            " [5 6 7 8 9]]\n",
            "[[ 0  1  2  3  4]\n",
            " [10 11 12 13 14]\n",
            " [20 21 22 23 24]]\n",
            "[[ 0  5]\n",
            " [10 15]\n",
            " [20 25]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping\n",
        "Reshaping is another key operation for manipulating tensors. Reshaping tensors, like arrays, can include switching, increasing, and decreasing dimensions. For example, you can change the three dimensional tensor into one dimension or two dimensions."
      ],
      "metadata": {
        "id": "kAnsigU4WYhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reshaping\n",
        "#https://www.tensorflow.org/api_docs/python/tf/reshape\n",
        "\n",
        "print(\"\\nOriginal tensor:\")\n",
        "print(sample_tensor)\n",
        "print(\"\\nShaped tensor:\")\n",
        "print(tf.reshape(sample_tensor,(2,3,5))) #switch first and second dimensions\n",
        "\n",
        "print(\"\\nCompare the size of the two tensors:\")\n",
        "print(tf.size(sample_tensor),tf.size(tf.reshape(sample_tensor,(2,3,5))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAqHTlmIhlvL",
        "outputId": "6b6d107c-5742-46a0-db6c-bea7537df243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original tensor:\n",
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n",
            "\n",
            "Shaped tensor:\n",
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]]\n",
            "\n",
            " [[15 16 17 18 19]\n",
            "  [20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32)\n",
            "\n",
            "Compare the size of the two tensors:\n",
            "tf.Tensor(30, shape=(), dtype=int32) tf.Tensor(30, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also change the 3-dimensional tensor to a 1-dimensional tensor"
      ],
      "metadata": {
        "id": "-D-v_xp5zFXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#flatten tensor\n",
        "print(tf.reshape(sample_tensor,(30)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAhOVc1Hfw67",
        "outputId": "7e62ef8e-db69-4454-c6de-3c00db2b33dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29], shape=(30,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or you can change it to two dimensions. "
      ],
      "metadata": {
        "id": "Fv0mggCiz7aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reduce to two dimensions\n",
        "print(tf.reshape(sample_tensor,(2,15)))\n",
        "print(tf.reshape(sample_tensor,(3,10)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr6SCYJQf4uY",
        "outputId": "5a94540f-e7c7-45c9-e51d-448ddee63d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
            " [15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]], shape=(2, 15), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5  6  7  8  9]\n",
            " [10 11 12 13 14 15 16 17 18 19]\n",
            " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, the size of the reshaped tensor must match the size of the original tensor. For example, the following code will not run without an error:"
      ],
      "metadata": {
        "id": "88mynebvDWXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this code will run with an error\n",
        "\n",
        "print(tf.reshape(sample_tensor,(2,10)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "j672TMU9DU6u",
        "outputId": "e4316f5e-7ca6-4693-b1c0-aa0ba246a8b2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-853e99059d0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#this code will run with an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 30 values, but the requested shape has 20 [Op:Reshape]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With reshaping, it is essential to be confident that the type of reshaping is appropriate for the task. If the sizes don't match, the code will return an error. Even harder to track down is reshaping where the sizes match, but the dimensions do not align with intended reshaping. This is important because with reshaping you can get bugs that do not throw errors but result in problems in the final model. "
      ],
      "metadata": {
        "id": "eyI1qmIW0A5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "You are working with a dataset with two-dimensional data (sample x data_dim1 x data_dim2). Use sample_tensor_2 for the input and complete the following challenges below. \n"
      ],
      "metadata": {
        "id": "jXSm8JapiZzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[[[2,4],[6,8]],\n",
        "      [[10,12],[14,16]],\n",
        "      [[1,3],[5,7]],\n",
        "      [[9,11],[13,15]],\n",
        "      ]\n",
        "sample_tensor_2=tf.stack(data)  \n",
        "print(sample_tensor_2.numpy())\n",
        "print(tf.shape(sample_tensor_2))"
      ],
      "metadata": {
        "id": "KL-inOfMjZgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a4729a-4b34-49b9-8d76-1e0d02c2ccd2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 2  4]\n",
            "  [ 6  8]]\n",
            "\n",
            " [[10 12]\n",
            "  [14 16]]\n",
            "\n",
            " [[ 1  3]\n",
            "  [ 5  7]]\n",
            "\n",
            " [[ 9 11]\n",
            "  [13 15]]]\n",
            "tf.Tensor([4 2 2], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) What is the total size of the dataset?\n",
        "\n",
        "2) How many samples are in the dataset? How many entries are there per sample?\n",
        "\n",
        "3) Index to select the third data sample.\n",
        "\n",
        "4) What do you predict the following code will do? What is the shape of the output?"
      ],
      "metadata": {
        "id": "Hzz_odBH2ZzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tensor_2[:,:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1e0Tz5z43ha",
        "outputId": "ade949b3-de1e-408b-c537-c7571e4976a6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\n",
              "array([[ 4,  8],\n",
              "       [12, 16],\n",
              "       [ 3,  7],\n",
              "       [11, 15]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) You want to choose the first two data samples in the tensor. The following code gives an error. What does the error mean? How would you fix the code?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aQhtsdOhNy5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reshape(sample_tensor_2,(3,2,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "jpDKjl74Nx3A",
        "outputId": "3c8443e6-dc6a-45fc-baa7-88dc0b33afa0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-eabfa483a3e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_tensor_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 16 values, but the requested shape has 12 [Op:Reshape]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Let's say we want to reshape the dataset to one-dimensional data for a simplified model (sample x data). What should the shape of the output to be? Does the code below achieve that goal? If not, correct it. "
      ],
      "metadata": {
        "id": "gzledRM85CL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reshape(sample_tensor_2,(4,4,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnGUbH0_ME_1",
        "outputId": "03a3e999-585c-4617-ee0d-1cd031811523"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4, 1), dtype=int32, numpy=\n",
              "array([[[ 2],\n",
              "        [ 4],\n",
              "        [ 6],\n",
              "        [ 8]],\n",
              "\n",
              "       [[10],\n",
              "        [12],\n",
              "        [14],\n",
              "        [16]],\n",
              "\n",
              "       [[ 1],\n",
              "        [ 3],\n",
              "        [ 5],\n",
              "        [ 7]],\n",
              "\n",
              "       [[ 9],\n",
              "        [11],\n",
              "        [13],\n",
              "        [15]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Solutions:\n",
        "#1) \n",
        "print('The size is:',tf.size(sample_tensor_2))\n",
        "#2) \n",
        "print('The number of samples is',tf.shape(sample_tensor_2)[0].numpy())\n",
        "print('The number of data per sample is',tf.shape(sample_tensor_2)[1].numpy()*tf.shape(sample_tensor_2)[2].numpy())\n",
        "#3)\n",
        "print(sample_tensor_2[2,:,:])\n",
        "#4) slice each sample for the second position in dimension 2, 4x2\n",
        "#5) The error is that the size of the reshape is not the same as the original \n",
        "# to do the operation in the question, index rather than reshape\n",
        "sample_tensor_2[:3,:,:]\n",
        "\n",
        "#6) The output should be 4x4. The provide code does 4x4x1, it needs to be changed to:\n",
        "tf.reshape(sample_tensor_2,(4,4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE_RqkNIOVey",
        "outputId": "5d242bb0-fe2a-45a9-d73d-94411f50afc9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size is: tf.Tensor(16, shape=(), dtype=int32)\n",
            "The number of samples is 4\n",
            "The number of data per sample is 4\n",
            "tf.Tensor(\n",
            "[[1 3]\n",
            " [5 7]], shape=(2, 2), dtype=int32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=int32, numpy=\n",
              "array([[ 2,  4,  6,  8],\n",
              "       [10, 12, 14, 16],\n",
              "       [ 1,  3,  5,  7],\n",
              "       [ 9, 11, 13, 15]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Revisiting Deep Learning\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6TR78IdDij7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives: \n",
        "- Code and optimize a neural network\n",
        "- Adapt a network to new data"
      ],
      "metadata": {
        "id": "6twFHgyZSeiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In previous sections of this course, you have covered neural networks and deep learning for classifying the MNIST dataset. In this section, we will revisit deep learning with Python with a few examples. \n",
        "\n",
        "We will start with the classificaton problem (student loan vs checking/savings account) from the NLP section of the course. We will use the same embeddings we trained for the final logistic regression problem in that section of the course.\n",
        "\n",
        "First, we will load in the data and split it into training and validation data."
      ],
      "metadata": {
        "id": "RRq8wjQaqiWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_features_df=pd.read_csv('embeddings.csv')\n",
        "y=pd.read_csv('y.csv')\n",
        "y_vals=y['Product_binary'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(word2vec_features_df, \n",
        "                                                    y_vals, \n",
        "                                                    train_size = .80, \n",
        "                                                    test_size=0.20, \n",
        "                                                    random_state = 10)\n"
      ],
      "metadata": {
        "id": "bMyrg9cv0pDS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "a46a0c56-6e38-4bfd-bce1-a57216849a43"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-fcdd77606791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword2vec_features_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'embeddings.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_vals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Product_binary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m X_train, X_test, y_train, y_test = train_test_split(word2vec_features_df, \n\u001b[1;32m      5\u001b[0m                                                     \u001b[0my_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'embeddings.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we define the model. In Keras, each layer of the model has to be individually specified. This allows significant control over the model, including different parameters for each level.\n",
        "\n",
        "This model has two dense layers with 128 neurons in each, and two dropout layers where 20% of the connections are dropped out for each layer. The final output layer uses a sigmoid activation function to create a final binary output (0 or 1). "
      ],
      "metadata": {
        "id": "qhyFnEKUh_uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NN_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    # A fully connected layer with 128 neurons\n",
        "    model.add(Dense(128, input_dim=301,activation='relu'))\n",
        "\n",
        "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # A fully connected layer with 128 neurons\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "\n",
        "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
        "    model.add(Dropout(.2))\n",
        "    \n",
        "    # An output layer with binary classification\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # Compile model with crossentropy\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "colGv5dcuzwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we fit and evaluate the model."
      ],
      "metadata": {
        "id": "8wH5KqiKiQQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"NN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "c9AXKsZQwVsR",
        "outputId": "cafc9369-696c-4847-819d-14e76dacc3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ee748e57e67f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Evaluation of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-4d341ec47b16>\u001b[0m in \u001b[0;36mNN_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mNN_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# A fully connected layer with 128 neurons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simple neural network with a couple of densely connected layers and a couple of dropout layers. When working with neural nets, it's often a good idea to start with a simple net to make sure the basics of the code work, then gradually create more complicated architectures once the code runs smoothly."
      ],
      "metadata": {
        "id": "EIN6sK82FQxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n"
      ],
      "metadata": {
        "id": "xTYiVkBM18Fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Adapt this model to another set of data. First, let's load in the MNIST digits dataset. We are going to flatten the data for now to create a two dimensional tensor with 784 columns to fit with the neural net we are working on. Note: instead of two classes, the MNIST dataset uses 10 classes (one for each digit 0-9). "
      ],
      "metadata": {
        "id": "LGLS9pEUibTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this model gives errors. fix it!\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to [samples][width][height][pixels]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28*28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28*28)\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZTIeDTnBn8o",
        "outputId": "01543509-49a7-435e-9923-613801db3e04"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the same code from the NN model above. What do you need to change in order to run the same model on the new data? Note which parameters and values you need to change. How does this relate to the differences in the data? Edit the code to work with the new data shape and execute it.\n",
        "\n",
        "Hint: use tf.shape() to see the compare the shapes of the MNIST and original dataset"
      ],
      "metadata": {
        "id": "_bP926VQjIJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def diff_CNN_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(128, input_dim=301,activation='relu')) #change input dim\n",
        "\n",
        "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    # A fully connected layer with 128 neurons\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.2))\n",
        "    \n",
        "    # An output layer with softmax as in MLP\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # Compile model as before in MLP\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "cSNA3QUO2CL0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = diff_CNN_model()\n",
        "# Fit the model\n",
        "print(X_train.shape)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"NN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uwgwXwsBeRe",
        "outputId": "1b29e275-6ea6-434b-ff27-0e7337a0799a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "Epoch 1/10\n",
            "300/300 - 1s - loss: 5.7785 - accuracy: 0.6342 - val_loss: 0.7637 - val_accuracy: 0.8248 - 1s/epoch - 4ms/step\n",
            "Epoch 2/10\n",
            "300/300 - 1s - loss: 0.8961 - accuracy: 0.7787 - val_loss: 0.5545 - val_accuracy: 0.8810 - 764ms/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "300/300 - 1s - loss: 0.6857 - accuracy: 0.8330 - val_loss: 0.4486 - val_accuracy: 0.8989 - 699ms/epoch - 2ms/step\n",
            "Epoch 4/10\n",
            "300/300 - 1s - loss: 0.5646 - accuracy: 0.8586 - val_loss: 0.3877 - val_accuracy: 0.9115 - 768ms/epoch - 3ms/step\n",
            "Epoch 5/10\n",
            "300/300 - 1s - loss: 0.4874 - accuracy: 0.8763 - val_loss: 0.3654 - val_accuracy: 0.9242 - 734ms/epoch - 2ms/step\n",
            "Epoch 6/10\n",
            "300/300 - 1s - loss: 0.4398 - accuracy: 0.8903 - val_loss: 0.3114 - val_accuracy: 0.9259 - 716ms/epoch - 2ms/step\n",
            "Epoch 7/10\n",
            "300/300 - 1s - loss: 0.3889 - accuracy: 0.9001 - val_loss: 0.2898 - val_accuracy: 0.9375 - 774ms/epoch - 3ms/step\n",
            "Epoch 8/10\n",
            "300/300 - 1s - loss: 0.3573 - accuracy: 0.9078 - val_loss: 0.2831 - val_accuracy: 0.9397 - 737ms/epoch - 2ms/step\n",
            "Epoch 9/10\n",
            "300/300 - 1s - loss: 0.3219 - accuracy: 0.9151 - val_loss: 0.2631 - val_accuracy: 0.9427 - 702ms/epoch - 2ms/step\n",
            "Epoch 10/10\n",
            "300/300 - 1s - loss: 0.3119 - accuracy: 0.9191 - val_loss: 0.2244 - val_accuracy: 0.9474 - 723ms/epoch - 2ms/step\n",
            "NN Error: 5.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Optimize NLP model\n",
        "\n",
        "The logit model from the challenge question in NLP section used to classify the customer complaint data had an accuracy of 78.5%. What is the accuracy of the first neural network model on the same data? Try changing the model to improve accuracy. What configuration gave you the best results? (Hint: you can look at the next section if you need inspiration)"
      ],
      "metadata": {
        "id": "lZj0IiVYjYtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here\n"
      ],
      "metadata": {
        "id": "fpMjqhdt3HKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Solution \n",
        "#1) \n",
        "def diff_CNN_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(128, input_dim=784,activation='relu')) #change input dim\n",
        "\n",
        "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    # A fully connected layer with 128 neurons\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.2))\n",
        "    \n",
        "    # An output layer with softmax as in MLP\n",
        "    model.add(Dense(10, activation='softmax')) #change dimension to number of categories\n",
        "    \n",
        "    # Compile model as before in MLP\n",
        "    #change to categorical crossentropy\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = diff_CNN_model()\n",
        "# Fit the model\n",
        "print(X_train.shape)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"NN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "#2) varies"
      ],
      "metadata": {
        "id": "VaH2yg7cSEdj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing Neural Nets\n"
      ],
      "metadata": {
        "id": "23KhRlCwGLSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "- Explore strategies to optimize a neural net\n",
        "- Implement an optimizer with custom settings\n",
        "- Grid search parameters"
      ],
      "metadata": {
        "id": "UOPuwHOBSt2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing neural nets is a key point of using these powerful models effectively, as with any ML models. However, neural nets have many parameters that can be tuned and are a challenge for traditional optmization methods such as grid search.\n",
        "\n",
        "In the previous challenge, we experimented with improving the accuracy of the model. The following strategies can help guide the optmization process for fine-tuning algorithms.\n",
        "\n",
        "1. Feature engineering (refer to Natural Language Processing Notebook)\n",
        "\n",
        "2. Try a smaller network (minimize redundancy) or a larger network (capture more complex relationships)\n",
        "\n",
        "3. Change learning rate\n",
        "4. Use appropriate architecture for the data/task\n",
        "\n",
        "5. Test parameters\n",
        "\n",
        "6. Decrease batch size \n",
        "\n",
        "Depending on the task, data, and neural network used, there may be a significant amount of tuning necessary in order to achieve an optimal result. This is one reason why leveraging existing models that are already optimized can give a huge advantage for language tasks. \n",
        "\n",
        "Further reference this article: https://towardsdatascience.com/optimizing-neural-networks-where-to-start-5a2ed38c8345 \n",
        "\n",
        "\n",
        "For this notebook we will start with changing the learning rate. \n",
        "\n",
        "In previous examples, we passed the optimizer to the compile funciton \n",
        "```\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "```\n",
        "Which uses the default parameters for the function. Now that we are customizing the parameters, we want to use the actual optimizer function, and then pass that optimizer into the .compile() function.\n",
        "\n",
        "```\n",
        "opt=keras.optimizers.Adam()\n",
        "```\n",
        "\n",
        "Here is the documentation for that function: https://keras.io/api/optimizers/adam/\n",
        "\n",
        "What is the default parameter for learning rate? What are some of the other parameters for the Adam optimizer?"
      ],
      "metadata": {
        "id": "WZjXK0-OGT5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Challenge\n",
        "\n",
        "1) Edit the code below to use the adam optimizer function with default parameters. \n",
        "\n",
        "2) Test the following learning rates: [.0001,.001,.01,.1]. Which one performs the best? Which one performs the worst?\n",
        "\n"
      ],
      "metadata": {
        "id": "ElzhbM-eOPDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load in data to use for this test\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#cnn classification for neural nets\n",
        "word2vec_features_df=pd.read_csv('embeddings.csv')\n",
        "y=pd.read_csv('y.csv')\n",
        "y_vals=y['Product_binary'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(word2vec_features_df, \n",
        "                                                    y_vals, \n",
        "                                                    train_size = .80, \n",
        "                                                    test_size=0.20, \n",
        "                                                    random_state = 10)\n",
        "#print(word2vec_features_df.shape)\n",
        "#print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "9DZBPIH2OObp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "94a5901c-8147-4bb2-e0dd-cf0ea8270271"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-df494cf5b31f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#cnn classification for neural nets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mword2vec_features_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'embeddings.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_vals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Product_binary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'embeddings.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) What if we wanted to systematically test a number of learning rates, for example with a for loop? \n",
        "\n",
        "Using the pseudocode below as a framework, create a loop to optimize learning rate. \n",
        "```\n",
        "learning-rate-list\n",
        "for rate in learning-rate-list:\n",
        "    train model\n",
        "    record accuracy\n",
        "select best model\n",
        "```\n",
        "Hint: non-linear sampling of the feature space can be helpful in generating a list of parameters to test.\n",
        "\n",
        "What was the best learning rate you found? What was the best error associated with it? Bonus: how long did this take with/without GPU?"
      ],
      "metadata": {
        "id": "OGKpTPRvTuoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#solution\n",
        "##1\n",
        "def NN_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(128, input_dim=301,activation='relu')) #change input dim\n",
        "\n",
        "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    # A fully connected layer with 128 neurons\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.2))\n",
        "    \n",
        "    # An output layer with softmax as in MLP\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    adam_opt=Adam(learning_rate=.1)\n",
        "    # Compile model as before in MLP\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "h8LXyHanPz9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN_model()\n",
        "# Fit the model\n",
        "print(X_train.shape)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "\n",
        "#2, #3 under construction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trjy8DMSQCGj",
        "outputId": "8093332a-e5ac-4148-a973-381b028079ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 301)\n",
            "Epoch 1/10\n",
            "4/4 - 1s - loss: 147.0860 - accuracy: 0.5450 - val_loss: 2.8241 - val_accuracy: 0.7850 - 925ms/epoch - 231ms/step\n",
            "Epoch 2/10\n",
            "4/4 - 0s - loss: 1.7689 - accuracy: 0.5713 - val_loss: 0.5360 - val_accuracy: 0.7850 - 36ms/epoch - 9ms/step\n",
            "Epoch 3/10\n",
            "4/4 - 0s - loss: 0.6445 - accuracy: 0.7862 - val_loss: 0.5481 - val_accuracy: 0.7850 - 33ms/epoch - 8ms/step\n",
            "Epoch 4/10\n",
            "4/4 - 0s - loss: 0.5769 - accuracy: 0.7763 - val_loss: 0.5450 - val_accuracy: 0.7850 - 38ms/epoch - 10ms/step\n",
            "Epoch 5/10\n",
            "4/4 - 0s - loss: 0.5661 - accuracy: 0.7862 - val_loss: 0.5327 - val_accuracy: 0.7850 - 34ms/epoch - 9ms/step\n",
            "Epoch 6/10\n",
            "4/4 - 0s - loss: 0.5716 - accuracy: 0.7850 - val_loss: 0.5289 - val_accuracy: 0.7850 - 34ms/epoch - 8ms/step\n",
            "Epoch 7/10\n",
            "4/4 - 0s - loss: 0.5317 - accuracy: 0.7862 - val_loss: 0.5231 - val_accuracy: 0.7850 - 38ms/epoch - 9ms/step\n",
            "Epoch 8/10\n",
            "4/4 - 0s - loss: 0.5239 - accuracy: 0.7862 - val_loss: 0.5207 - val_accuracy: 0.7850 - 36ms/epoch - 9ms/step\n",
            "Epoch 9/10\n",
            "4/4 - 0s - loss: 0.5213 - accuracy: 0.7862 - val_loss: 0.5206 - val_accuracy: 0.7850 - 49ms/epoch - 12ms/step\n",
            "Epoch 10/10\n",
            "4/4 - 0s - loss: 0.5182 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7850 - 44ms/epoch - 11ms/step\n",
            "CNN Error: 21.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Neural Nets"
      ],
      "metadata": {
        "id": "zVeckcZeGJvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[optional: if there are key architectures that need to be developed/described this would be a good place to do so]\n",
        "For the purpose of this notebook we have been doing has been to give basic strategies and tools for dealing with neural nets. In practice, your net will involve more complex architectures and properties. For example, you may include convolutional layers, preprocessing layers, regularization layers, and recurrent layers.  \n",
        "\n"
      ],
      "metadata": {
        "id": "4qLLJXRLHdQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huggingface"
      ],
      "metadata": {
        "id": "v5Ovl5RF2DjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "- Explore tasks and data available in Huggingface transformers\n",
        "- Choose an appropriate language task\n",
        "- Implement a transformer on local data"
      ],
      "metadata": {
        "id": "DRXZt7DhS7mR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In reality, these models  require significant data and computational power, which can exceed the resources available to the analyst. We can circumvent this problem by using pre-trained models. Like a pre-trained embedding models, pre-trained models are trained on a large dataset. While this may not perfectly align with the data or task you have, it can help create a more robust system, and the models can be fine-tuned to your data and goals.\n",
        "\n",
        "[Huggingface](https://huggingface.co/models) is a set of pretrained models from a variety of datasets and sources with an easy-to-use interface. In this section, we will explore the use of the Huggingface library to streamline language task processing.\n",
        "\n"
      ],
      "metadata": {
        "id": "glKdUE_CEw7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install the transformers library\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE52xADz3Py-",
        "outputId": "37c3d66a-57aa-4d36-93c9-3ff04d739525"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[?25l\r\u001b[K     |                                | 10 kB 42.5 MB/s eta 0:00:01\r\u001b[K     |▏                               | 20 kB 48.1 MB/s eta 0:00:01\r\u001b[K     |▎                               | 30 kB 47.8 MB/s eta 0:00:01\r\u001b[K     |▍                               | 40 kB 49.9 MB/s eta 0:00:01\r\u001b[K     |▌                               | 51 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |▋                               | 61 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |▊                               | 71 kB 28.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 81 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |▉                               | 92 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 102 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 112 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 122 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 133 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 143 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 153 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 163 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 174 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 184 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 194 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 204 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 215 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 225 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 235 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 245 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 256 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 266 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 276 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 286 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 296 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 307 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 317 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 327 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 337 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 348 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 358 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 368 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 378 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 389 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 399 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 409 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 419 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 430 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 440 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 450 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 460 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 471 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 481 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 491 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 501 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 512 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 522 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 532 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 542 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 552 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 563 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 573 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 583 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 593 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 604 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 614 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 624 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 634 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 645 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 655 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 665 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 675 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 686 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 696 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 706 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 716 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 727 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 737 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 747 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 757 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 768 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 778 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 788 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 798 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 808 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 819 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 829 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 839 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 849 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 860 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 870 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 880 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 890 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 901 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 911 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 921 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 931 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 942 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 952 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 962 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 972 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 983 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 993 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 1.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 1.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 1.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 1.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 1.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 1.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 1.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 1.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 1.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 1.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 1.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 1.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 1.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 1.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 1.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 1.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 1.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 1.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 1.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 1.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 1.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 1.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 1.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 1.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 1.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 1.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 2.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 2.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 2.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 2.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 2.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 2.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 2.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 2.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 2.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 2.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 2.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 2.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 2.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 2.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 2.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 2.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 2.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 2.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 2.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 2.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 2.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 2.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 2.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 2.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 2.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 2.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 2.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 2.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 2.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 2.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 2.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 2.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 2.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 2.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 2.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 2.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 2.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 2.4 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 2.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 2.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 2.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 2.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 2.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 2.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 2.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 2.5 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 2.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 2.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 2.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 2.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.6 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 2.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 2.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.7 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 2.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.8 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.9 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 3.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 3.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 3.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 3.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 3.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 3.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 3.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.0 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 3.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 3.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 3.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 3.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 3.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 3.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 3.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 3.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.1 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 3.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 3.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 3.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 3.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 3.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 3.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 3.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 3.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.2 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 3.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 3.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 3.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 3.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 3.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 3.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 3.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 3.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.3 MB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.4 MB 32.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 66.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 70.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simplest strategy is to use the pipeline method, where you select the task and the pre-trained model (there are multiple models available for many of the tasks)"
      ],
      "metadata": {
        "id": "WygeyX2MQo8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\") \n"
      ],
      "metadata": {
        "id": "V9pq4nvXSnMh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183,
          "referenced_widgets": [
            "c8a86d4a4f00485ab53dd4f186dd7923",
            "4adbee71dccb44788b2e8a38086bd740",
            "4a4dbf5952ea47b29525d67e31e0f6d8",
            "67542e1598204918863250f7ccb19f45",
            "e52415d9a93b40809ce72af204017356",
            "81b6c6649c3348fd972d6e922f447b7a",
            "6a3dd8bb6d254dbe9ff078e01d69af54",
            "192b1683f74244609ab990f86c4d50a0",
            "974637d371c5458c86c8c817ed7d546c",
            "93025786d1db4b71bd839a32152ff0ff",
            "8e3ce28b50f44f7584dd1f9bdb86e63b",
            "5ba74fea58594764b917cca9898f6789",
            "da3afbc514df48b4ab32a3762de4b11e",
            "099a63f668bb41b3b696040101a743c2",
            "4c22aece7bc34948bb6fa7dd7211c489",
            "32d57eee7e0a4328ab5be9fa45b5c466",
            "834c835a023049e797c97088f80620c9",
            "764762ff43a544f0a60ce87cbbb96f98",
            "ddac78a3c1f84da1b1fce8f86143328c",
            "089f32eb33d64f9eba137033bbb1c447",
            "fb4448827a0d452a876389c7c9963956",
            "f6aac0ac6c95475aa852b980ca4936cd",
            "778f78a61330498fa51d1a9c20c9f3ba",
            "e9d7b29295a94a95ae9aa711386c6a1c",
            "33e581c215384e51be58035219329b91",
            "647eedfeb3134499b524b66fb06e1587",
            "2e7f2e6d27e242a2a089f686ffab55a5",
            "d461230c7a634df786353d3595b337db",
            "f4ca43dac4f04b8cb7b1be631b3a919b",
            "1108d5c375234c7facd9d19481be8d2c",
            "e920e80a5be04092b7744c30aa49afeb",
            "5d5efd77976e4b70ae3984ca5157f1d9",
            "c8e8cfb841594d6fa734215119e87016",
            "79b5f56a61f3422880aa72c012ee1a5e",
            "eda808930d05426ab516fe5c6766cc83",
            "0319b3fcb679423fb68966c2e17d8a55",
            "25b5b10ddb8749efb9dddca1e18a0f23",
            "cb1dcb6aff094b0ea40a15c0472ce5d9",
            "50991ea0da224d6182d1e4dbfc23a2e4",
            "9a9f7d048b33408f97aa23614c3936a8",
            "ca9a6865dbf04b1b9f73ab7436c5623a",
            "9329b12596734c87b6d5b381ad93c366",
            "67f0c531d5754addac406e02a4c76e11",
            "087b592f2da34d32832b74236b652f5b"
          ]
        },
        "outputId": "e92182a2-4dea-434e-a90f-6a06e2dbc8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8a86d4a4f00485ab53dd4f186dd7923",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ba74fea58594764b917cca9898f6789",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "778f78a61330498fa51d1a9c20c9f3ba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79b5f56a61f3422880aa72c012ee1a5e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key to using these models, since the preprocessing is built in, is understanding the format of the data necessary for the model. This model takes the raw text as input rather than the word embeddings, so let's reload our data appropriately."
      ],
      "metadata": {
        "id": "cdXQGdLgQ9sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfpb=pd.read_csv('CFPB 2020 Complaints.csv')\n",
        "complaints=cfpb['Consumer complaint narrative']\n",
        "complaints=complaints[~complaints.isna()]\n",
        "classifier(complaints.values[0])\n",
        "print(complaints.values[0])"
      ],
      "metadata": {
        "id": "Iahhf3AEUGBN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "b1de1719-1bbe-4181-ccc7-b251c9bc1c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-5a00b6d67044>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcfpb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CFPB 2020 Complaints.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcomplaints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfpb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Consumer complaint narrative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcomplaints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplaints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mcomplaints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplaints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplaints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CFPB 2020 Complaints.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then use the pipeline on the example data, and look at the results."
      ],
      "metadata": {
        "id": "7_rQGYoPRNon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ex"
      ],
      "metadata": {
        "id": "Thjw7tTaRSgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While this doesn't work for every task, for example the specific classification task that we were working with above, this is a valuable and powerful tool for quick, out-of-the-box models that don't take very long to initialize and tune."
      ],
      "metadata": {
        "id": "eGFiOhimXOYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge \n",
        "\n",
        "1) Choose one task  from the [huggingface](https://huggingface.co/docs/transformers/task_summary). Select the task, model, and build a pipeline. What format should the data be in? What preprocessing steps are included in the model, if any?Run it on the cfpb data. Interpret the results. What challenges do you run into?\n",
        "\n",
        "2) How do different pre-trained models perform on the same task with the same data?\n"
      ],
      "metadata": {
        "id": "GP_oJhO0WcJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Steps\n",
        "\n",
        "This lab has introduced Colab as a way to use GPUs to speed up processing power and explored further applications of deep learning to natural language processing. \n",
        "\n",
        "In practice, using deep learning for computational social science requires building on the foundational concepts covered in this notebook to implement models with more complicated data and architecture. However, there are many strategies can help you navigate the model ecosystem, some of which we will discuss here: \n",
        "\n",
        "1. Documentation (and other resources like tutorials) is a goldmine of information for implementing particular algorithms and completing specific tasks. This is one reason why reading and translating code written by others is a key skill. \n",
        "\n",
        "2. Debugging and interpreting error messages, as well as leveraging online resources in order to resolve them, is another key concept. Resources like documentation and Stack Overflow help solve common errors and get code working faster. In addition, checking your code as you go and forming expectations of the results at each step will also help you to code smoothly.\n",
        "\n",
        "3. Computational resources are important for running complex models. Google Colab has access to GPUs, but does have limitations for large and extended jobs. In those cases, options are: [add further resources here]\n",
        "\n",
        "4. Further resources [add some books on deep learning and nlp]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0yLbtugXYBqV"
      }
    }
  ]
}