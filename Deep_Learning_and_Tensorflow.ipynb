{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning and Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvYdWn2GKTT1BcwXRD8TeD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a74a3c514144ee3a3bf386fbb3dbc8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_13b694993ab747ffa0b563134cc361b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_112c02c165ad4ea992314b4b5fbc645d",
              "IPY_MODEL_fc5dbb1d102d41cfa0c20bbbb3c38f0e",
              "IPY_MODEL_15558253f80d45d0801a0f93beb9e00c"
            ]
          }
        },
        "13b694993ab747ffa0b563134cc361b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "112c02c165ad4ea992314b4b5fbc645d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_94ec5dafdb1d4b08ac8c5f08259bae65",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a0e9ae8bca1429e875d8e359d809f15"
          }
        },
        "fc5dbb1d102d41cfa0c20bbbb3c38f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_37824a7ff684403189f05376eb56209d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 629,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 629,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_facfb260eaa147018472e1fa2f2f1332"
          }
        },
        "15558253f80d45d0801a0f93beb9e00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5610b039845d4274ac54c018e18171a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 629/629 [00:00&lt;00:00, 4.70kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ebcefab8184477f961812e2764ebf57"
          }
        },
        "94ec5dafdb1d4b08ac8c5f08259bae65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a0e9ae8bca1429e875d8e359d809f15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37824a7ff684403189f05376eb56209d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "facfb260eaa147018472e1fa2f2f1332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5610b039845d4274ac54c018e18171a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ebcefab8184477f961812e2764ebf57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a82642ae5e34f43832b9c9cff277944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f0b3f3cf63f74f0cac5d84cfb3acc1bb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5124c1bb783c45a2886c742aa79bcf87",
              "IPY_MODEL_1205c7b7d6f641c38c33444a382d43b1",
              "IPY_MODEL_659fbe0a060b496cbee4a0a1be51a925"
            ]
          }
        },
        "f0b3f3cf63f74f0cac5d84cfb3acc1bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5124c1bb783c45a2886c742aa79bcf87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e1650fe6592464fa83082995a768901",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00b4d9bc69fa4ef29f8a5336f64ea449"
          }
        },
        "1205c7b7d6f641c38c33444a382d43b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_49ffd5892b0947c7bd49fc1b7630a01a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267844284,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267844284,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7552ea24d6754ebab80240c39dbf29f0"
          }
        },
        "659fbe0a060b496cbee4a0a1be51a925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_de1699df1e164930bf8852efdced8536",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 255M/255M [00:26&lt;00:00, 11.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b451b768dc5e477dabe14fc7a3f0f5e1"
          }
        },
        "2e1650fe6592464fa83082995a768901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00b4d9bc69fa4ef29f8a5336f64ea449": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49ffd5892b0947c7bd49fc1b7630a01a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7552ea24d6754ebab80240c39dbf29f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de1699df1e164930bf8852efdced8536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b451b768dc5e477dabe14fc7a3f0f5e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a226f52e8f714f548bddd8a5269e5f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c672d449f6be4a2687700fded7dc3494",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ab70c84ac9146358226cb827e20c6db",
              "IPY_MODEL_cd1abde25fec4a99ace1a06625be18b8",
              "IPY_MODEL_e278b88b2bd2458bb773c2ee41192863"
            ]
          }
        },
        "c672d449f6be4a2687700fded7dc3494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ab70c84ac9146358226cb827e20c6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e8336756689478a9da33f53fa58f1ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e633e8fc58d4c3cacaf772135bfe096"
          }
        },
        "cd1abde25fec4a99ace1a06625be18b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ce5685da74d546119f39afb98c589deb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 48,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 48,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62285f407a8746ab9f282fbad75995fb"
          }
        },
        "e278b88b2bd2458bb773c2ee41192863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b028e0255c84020b7630ba7ea5f1d15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 48.0/48.0 [00:00&lt;00:00, 262B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20cf93c3b9ef4d7c8aa347792bbd57ff"
          }
        },
        "3e8336756689478a9da33f53fa58f1ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e633e8fc58d4c3cacaf772135bfe096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce5685da74d546119f39afb98c589deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62285f407a8746ab9f282fbad75995fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b028e0255c84020b7630ba7ea5f1d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20cf93c3b9ef4d7c8aa347792bbd57ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b7b6c4d914e48f7b367514ea5ad4ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_70aed85c10474e24afee02f4d0ce191c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_34916cb450b24154b37f28c38760f0e5",
              "IPY_MODEL_6d653345f271408d892c331643aad030",
              "IPY_MODEL_8551d92d168e43538415c39563c079a7"
            ]
          }
        },
        "70aed85c10474e24afee02f4d0ce191c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34916cb450b24154b37f28c38760f0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb522df2753f4f91bf2a192069f34bde",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be861d7f0c854931b13d4fbe564aac2d"
          }
        },
        "6d653345f271408d892c331643aad030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2da71e7640de40138b657387888ed34f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e237e7f86eee47c9958d6ff5595c13f4"
          }
        },
        "8551d92d168e43538415c39563c079a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a7d7699eed024c2ebfebde18e9135c38",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 9.37kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a373404de174f7e935246e403757a16"
          }
        },
        "cb522df2753f4f91bf2a192069f34bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be861d7f0c854931b13d4fbe564aac2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2da71e7640de40138b657387888ed34f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e237e7f86eee47c9958d6ff5595c13f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7d7699eed024c2ebfebde18e9135c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a373404de174f7e935246e403757a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlab-berkeley/Computational-Social-Science-Training-Program/blob/master/Deep_Learning_and_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GPU, Deep Learning, and Tensorflow**\n"
      ],
      "metadata": {
        "id": "0DrTKxZ1hCS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will introduce you to the fundamentals of Tensorflow and explore techniques for deep learning with text data. Key concepts covered in this notebook include:\n",
        "\n",
        "1. Google Colab and GPUs\n",
        "2. Tensors and basic tensor operations\n",
        "3. Use tensorflow/keras to adapt and tune neural nets\n",
        "4. Existing resources to help analyze language data\n",
        "\n",
        "\n",
        "With these basic building blocks, you will be equipped to explore and implement deep learning algorithms for your own project. "
      ],
      "metadata": {
        "id": "XHoISf71wzH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wNqj6s9msZga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "\n",
        "- Set up a Google Colab notebook\n",
        "- Create, delete, run, and edit cells\n",
        "- Cover variable, notebook and package management"
      ],
      "metadata": {
        "id": "gNovoJcyugcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducing Google Colab\n",
        "\n",
        "\n",
        "Google Colab is a platform for cloud-based computation and coding. It can be thought of as similar to a jupyter notebook, where individual cells can be executed with code inside. It doesn't require local installation on your computer and can be shared and edited by multiple people at the same time. However the Colab notebook requires you to be connected to the internet, while in comparison jupyter notebooks can be run on your machine offline. Google Colab notebooks are in the .ipynb format, and can be saved and opened either directly or via Google Drive. \n",
        "\n"
      ],
      "metadata": {
        "id": "L_zANHRDhplZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basic Operations\n",
        "\n",
        "Google Colab has several features that help organize code and long notebooks. A few key concept to know to use this notebook effectively are:\n",
        "\n",
        "- Use the Insert tab in the upper bar, or press the +Code/+Text buttons in the top left of the window.\n",
        "\n",
        "- ctrl/cmd +alt +n opens a scratch cell. This is a place to test code without needing to edit the main notebook.\n",
        "\n",
        "- Text cells can be edited and formatting with the buttons at the top of the cell.\n",
        "\n",
        "- The buttons at the top right of the cell give you options to move, modify and delete the cell. \n",
        "\n",
        "- You can run code with shift+enter, or by clicking the top left of the box.\n",
        "\n",
        "- For more commands, use ctl+shift+p and select the desired command from the command palette\n",
        "\n",
        "An example code cell is below:"
      ],
      "metadata": {
        "id": "oqx972vJvdVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Welcome to Google Colab\")\n",
        "x=12+78"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhl6KsHCrLP-",
        "outputId": "edc15391-16d6-49f0-b5dd-78bf76439d83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Google Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The buttons on the left panel help manage the notebook (search, table of contents, files). This is important for organizing your code and navigating long notebooks.\n",
        "\n"
      ],
      "metadata": {
        "id": "pT9L_Th9sPrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package Management\n",
        "\n",
        "Like Anaconda, Google Colab comes with many packages already available, and you can also install local packages using pip. Use the following lines of code in order to see which packages you have and which ones you need to install. Because this runs on the cloud, I suggest checking the packages here to confirm that you have the right ones for your project. \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "#check which packages you have available (listed alphabetically). The version numbers are also avaliable which can be useful in determining issues with coding between computers.\n",
        "!pip list\n",
        "\n",
        "#install a new package\n",
        "!pip install numpy \n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<List of packages that we will use in this tutorial>"
      ],
      "metadata": {
        "id": "VR9JpuTHcmVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell are the packages that you will need to complete this notebook:"
      ],
      "metadata": {
        "id": "fQ3GQZB7bo6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages for deep learning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "Qey74xT0boGX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customization\n",
        "\n",
        "Finally, there are several settings that you can customize if you so choose. These can be found under Tools -> Settings, where you can change the font size, background, and other aesthetic settings of the notebook to suit you. \n",
        "\n",
        "In addition, in Tools -> Keyboard shortcuts you can view and adapt shortcuts to your preferences as well.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pi2ikVCaoNct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "Try out the following exercises to get comfortable with the new interface:\n",
        "\n",
        "1) Open the editor settings (Tools-> Settings->Editor) and select \"Show line numbers\". Now your cells will have line numbers next to them, which we can refer to when discussing code during this workshop.\n",
        "\n",
        "2) Make a new code cell below and save the product of 60 and 72 to a new variable. Then check the value of the variable in the variable tab to the left.\n"
      ],
      "metadata": {
        "id": "EHrAjcLHsYC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "print(\"Turn me into a code cell\")"
      ],
      "metadata": {
        "id": "2DWqUetbmeoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#solutions\n",
        "#1) follow the directions in the question\n",
        "#2) \n",
        "new = 60*72\n"
      ],
      "metadata": {
        "id": "R2iLcnJj1-Ng"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to GPU"
      ],
      "metadata": {
        "id": "A58nCiMsshpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "- Understand the benefits of GPUs\n",
        "- Set up GPU for Google Colab\n",
        "- Compare performance on tasks vs CPU"
      ],
      "metadata": {
        "id": "L1AkXBaoujUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you've found in your previous models, some models take a significant amount of time to run. Models may also exceed the capacity of the local computer's processing power. This will either result in code that never finished running, or an error message indicating that the code has timed out without completing. \n",
        "\n",
        "To counteract this issue, TPU/GPU are parallel processing units that greatly speed up models. This can make some models that are otherwse impossible to train possible (Think minutes rather than hours)\n",
        "\n",
        "TPU is made specifically for tensorflow architecture, and speeds it up even more than GPUs.\n",
        "\n",
        "## GPU Access\n",
        "Oftentimes you need to pay for cloud services and access to GPUs, but one advantage of Colab is that it has free access to a certain amount of GPU/TPU units. This access is somewhat limited, but should be more than enough for what we are using it for today. We will discuss limitations and further options for long-term use in a later section of the workshop.\n",
        "\n",
        "\n",
        "Additional resource: https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=sXnDmXR7RDr2"
      ],
      "metadata": {
        "id": "xp2UXU5HHTSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The notebook will automatically choose which device (read: GPU vs CPU) to run the code on, but if you want to make sure that something is being run on a certain device, you can select a specific device as in the snippet below. \n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "with tf.device(device_name):\n",
        "  #put task here\n",
        "  #return output\n",
        "```\n",
        "\n",
        "For now, we will trust the notebook's/ Tensorflow's allocation of computing power.\n",
        "\n"
      ],
      "metadata": {
        "id": "co9jxID0Utsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "1) Run the following lines of code to test how fast your computer can do a task. Report the results\n"
      ],
      "metadata": {
        "id": "F9xyYBVVRZlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "print(timeit.timeit('[x**2 for x in range(10)]'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqgQQ2a1SBDj",
        "outputId": "46f5ae18-3f14-42e7-a0ad-c269fc4e9515"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.2927398080000785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)  Change the settings to use GPU:  Edit --> Notebook Settings --> Hardware Accelerator --> GPU\n",
        ". Run the code below to make sure GPU is enabled."
      ],
      "metadata": {
        "id": "yx9qArhdR-31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#run this code to check that you have the GPU enabled\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow0GhY3ANepm",
        "outputId": "3b96fcac-bffb-416c-ec14-4f11816e7227"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Re-run the same timing task and report your results. How much of a difference is there in timing?"
      ],
      "metadata": {
        "id": "L6kl-9FvVbBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "print(timeit.timeit('[x**2 for x in range(10)]'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9ADVC5SVabz",
        "outputId": "4ba3f95e-3047-45f3-ca52-541a020f1c6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.587992389000192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we run more complex tasks, the efficiency of GPUs becomes more and more of a difference. If you are curious, you can compare the timing of the tasks in this notebook with GPU/TPU/CPU and note the difference. Even though in this notebook we are working with fairly small dataset and task, these differences will be important at larger scale."
      ],
      "metadata": {
        "id": "8GvtUiHVV6IO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manpulating Tensors"
      ],
      "metadata": {
        "id": "Q_hXKH0wu5XL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "- Understand the tensor data type\n",
        "- Index, reshape, and slice tensors"
      ],
      "metadata": {
        "id": "8L9b-y83u6bR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Neural Networks section of the course, you were introduced to Multilayer Perceptrons (MLP) as a basic building block of neural networks. You were also introduced to using Keras to build a neural network for digit recognition. Neural networks are powerful deep learning tools that can learn complex relationships in data. In this section we will further explore the powerful Keras/Tensorflow framework for neural networks.\n",
        "\n",
        "First, we will cover tensors, which are an essential concept for interacting with deep learning models. Tensors are the key data structure in Tensorflow and are simlar to numpy arrays but can be used with GPUs. Tensors have one or more dimensions, are rectangular, and are immutable. Every entry in a tensor must have the same datatype (usually float).\n",
        "\n",
        "A 3-dimensional tensor can be visually represented in a few different ways. It can be represented as a mxnxp dimensional block:\n",
        "\n",
        "\n",
        "![3-axis_block.png](https://drive.google.com//uc?id=1ZQIeFD5zm-Nnh28bfgooXnb0AqlaWNzB)\n",
        "\n",
        "\n",
        "Or the block can be flattened out to three mxn dimensional arrays:\n",
        "\n",
        "![3-axis_numpy.png](https://drive.google.com//uc?id=1TyHhSZ66fJcFYGGkHrnmI3ZlNZ7-5RJW)\n",
        "\n",
        "\n",
        "The *shape* of this tensor is 5x3x2 and the *size* is 30, since there are 30 total units in the tensor. Although they are harder to visualize, tensors can have many dimensions.\n",
        "\n",
        "\n",
        "In Tensorflow, since we are handling every step of the process, tracking the dimensions, shapes, sizes of the tensors is an essential skill for working with this code. \n",
        "\n",
        "Images from:  https://www.tensorflow.org/guide/tensor"
      ],
      "metadata": {
        "id": "FGfJ5yBMaDa0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Operations\n",
        "\n",
        "Just like manipulating dataframes or arrays, manipulating tensors is an important skill. There are some basic tensor operations that it is useful to be aware of for manipulating tensors. We will explore these with the same example tensor from above."
      ],
      "metadata": {
        "id": "oHzdlBc3dtqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a tensor from an array\n",
        "\n",
        "Tensors are similar to numpy array and tensorflow will automatically convert an array to a tensor when using tensorflow operations. Similarly, .numpy() can convert a tensor to an array.\n",
        "\n",
        "\n",
        "More commonly, you will most likely be using methods that process data and output a tensor that you can then work with, and most conversions to tensors will be handled automatically within those methods. "
      ],
      "metadata": {
        "id": "Y6f-T3hs4GR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data=np.array([[[0,1,2,3,4],[5,6,7,8,9]],\n",
        "      [[10,11,12,13,14],[15,16,17,18,19]],\n",
        "      [[20,21,22,23,24],[25,26,27,28,29]]])\n",
        "print('The original data type is:',type(data))\n",
        "sample_tensor=tf.concat(data,2)\n",
        "print('The new data type is:',type(sample_tensor))\n",
        "print(sample_tensor)\n",
        "print(sample_tensor.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GUXRFkAe59o",
        "outputId": "811b7be9-7e6b-47f4-f7fd-0febd5a2d23e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original data type is: <class 'numpy.ndarray'>\n",
            "The new data type is: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int64)\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Indexing\n",
        "Indexing allows you to select subsections of the tensor. This is a very useful skill, but can get confusing with high dimensions. You can select a single number, or range of numbers in the tensor by specifying the position of the number in each dimension."
      ],
      "metadata": {
        "id": "Rhd9K7eQU8AE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get a single number\n",
        "sample_tensor[0,0,0]\n",
        "print(sample_tensor[0,0,0].numpy()) #.numpy() converts it to an array to print\n",
        "\n",
        "#get a range of values\n",
        "print(sample_tensor[0:2,1:2,:3].numpy()) \n",
        "\n",
        "\n",
        "#to take all items in a dimension:\n",
        "print(sample_tensor[0,:,:].numpy())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gLiSuEke8RK",
        "outputId": "b7c52cb4-05fc-4c7c-9a0e-36eb0c75e511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[[[ 5  6  7]]\n",
            "\n",
            " [[15 16 17]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping\n",
        "Reshaping is another key operation for manipulating tensors. Reshaping tensors, like arrays, can include switching, increasing, and decreasing dimensions. For example, you can change the three dimensional tensor into one dimension or two dimensions. The best way to understand the arguments for reshaping is to practice and look at examples. A series of sample reshapings are given below."
      ],
      "metadata": {
        "id": "kAnsigU4WYhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reshaping\n",
        "#https://www.tensorflow.org/api_docs/python/tf/reshape\n",
        "\n",
        "print(\"\\nOriginal tensor:\")\n",
        "print(sample_tensor)\n",
        "print(\"\\nShaped tensor:\")\n",
        "print(tf.reshape(sample_tensor,(2,3,5))) #switch first and second dimensions\n",
        "\n",
        "print(\"\\nCompare the size of the two tensors:\")\n",
        "print(tf.size(sample_tensor),tf.size(tf.reshape(sample_tensor,(2,3,5))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAqHTlmIhlvL",
        "outputId": "6b6d107c-5742-46a0-db6c-bea7537df243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original tensor:\n",
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n",
            "\n",
            "Shaped tensor:\n",
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]]\n",
            "\n",
            " [[15 16 17 18 19]\n",
            "  [20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32)\n",
            "\n",
            "Compare the size of the two tensors:\n",
            "tf.Tensor(30, shape=(), dtype=int32) tf.Tensor(30, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also change the 3-dimensional tensor to a 1-dimensional tensor"
      ],
      "metadata": {
        "id": "-D-v_xp5zFXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#flatten tensor\n",
        "print(tf.reshape(sample_tensor,(30)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAhOVc1Hfw67",
        "outputId": "7e62ef8e-db69-4454-c6de-3c00db2b33dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29], shape=(30,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or you can change it to two dimensions. "
      ],
      "metadata": {
        "id": "Fv0mggCiz7aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reduce to two dimensions\n",
        "print(tf.reshape(sample_tensor,(2,15)))\n",
        "print(tf.reshape(sample_tensor,(3,10)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr6SCYJQf4uY",
        "outputId": "5a94540f-e7c7-45c9-e51d-448ddee63d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
            " [15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]], shape=(2, 15), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5  6  7  8  9]\n",
            " [10 11 12 13 14 15 16 17 18 19]\n",
            " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, the size of the reshaped tensor must match the size of the original tensor. For example, the following code will not run without an error:"
      ],
      "metadata": {
        "id": "88mynebvDWXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this code will run with an error\n",
        "\n",
        "print(tf.reshape(sample_tensor,(2,10)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "j672TMU9DU6u",
        "outputId": "e4316f5e-7ca6-4693-b1c0-aa0ba246a8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-853e99059d0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#this code will run with an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 30 values, but the requested shape has 20 [Op:Reshape]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With reshaping, it is essential to be confident that the type of reshaping is appropriate for the task. If the sizes don't match, the code will return an error. Even harder to track down is reshaping where the sizes match, but the dimensions do not align with intended reshaping. This is important because with reshaping you can get bugs that do not throw errors but result in problems in the final model. "
      ],
      "metadata": {
        "id": "eyI1qmIW0A5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[[[2,4],[6,8]],\n",
        "      [[10,12],[14,16]],\n",
        "      [[1,3],[5,7]],\n",
        "      [[9,11],[13,15]],\n",
        "      ]\n",
        "sample_tensor_2=tf.stack(data)  \n",
        "print(sample_tensor_2.numpy())\n",
        "print(tf.shape(sample_tensor_2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2-hzVtJUq6V",
        "outputId": "8d087d4a-729b-4901-f793-0cdca12e072d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 2  4]\n",
            "  [ 6  8]]\n",
            "\n",
            " [[10 12]\n",
            "  [14 16]]\n",
            "\n",
            " [[ 1  3]\n",
            "  [ 5  7]]\n",
            "\n",
            " [[ 9 11]\n",
            "  [13 15]]]\n",
            "tf.Tensor([4 2 2], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "Use sample_tensor_2 for the input and complete the following challenges below. \n"
      ],
      "metadata": {
        "id": "jXSm8JapiZzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) What is the total size of the dataset?\n",
        "\n",
        "2) How many samples are in the dataset? How many entries are there per sample?\n",
        "\n",
        "3) What do you predict the following code will do? What is the shape of the output?"
      ],
      "metadata": {
        "id": "Hzz_odBH2ZzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tensor_2[:,:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1e0Tz5z43ha",
        "outputId": "ade949b3-de1e-408b-c537-c7571e4976a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\n",
              "array([[ 4,  8],\n",
              "       [12, 16],\n",
              "       [ 3,  7],\n",
              "       [11, 15]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Solutions:\n",
        "#1) \n",
        "print('The size is:',tf.size(sample_tensor_2))\n",
        "#2) \n",
        "print('The number of samples is',tf.shape(sample_tensor_2)[0].numpy())\n",
        "print('The number of data per sample is',tf.shape(sample_tensor_2)[1].numpy()*tf.shape(sample_tensor_2)[2].numpy())\n",
        "\n",
        "#3) slice each sample for the second position in dimension 2, 4x2\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE_RqkNIOVey",
        "outputId": "5d242bb0-fe2a-45a9-d73d-94411f50afc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size is: tf.Tensor(16, shape=(), dtype=int32)\n",
            "The number of samples is 4\n",
            "The number of data per sample is 4\n",
            "tf.Tensor(\n",
            "[[1 3]\n",
            " [5 7]], shape=(2, 2), dtype=int32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=int32, numpy=\n",
              "array([[ 2,  4,  6,  8],\n",
              "       [10, 12, 14, 16],\n",
              "       [ 1,  3,  5,  7],\n",
              "       [ 9, 11, 13, 15]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping a dataset"
      ],
      "metadata": {
        "id": "mZwpIEHed_9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An important skill is being able to reshape a dataset into a shape approprate for a given model. For example, tensor from the challenges above was three dimensions, with two dimensions of features per sample."
      ],
      "metadata": {
        "id": "vtToiL2TUrj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_tensor_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPx074SSeF_J",
        "outputId": "e6945df9-e55e-45d4-da12-abaa3a2c80d1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 2  4]\n",
            "  [ 6  8]]\n",
            "\n",
            " [[10 12]\n",
            "  [14 16]]\n",
            "\n",
            " [[ 1  3]\n",
            "  [ 5  7]]\n",
            "\n",
            " [[ 9 11]\n",
            "  [13 15]]], shape=(4, 2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, many common neural networks would expect 1-dimensional data as an input, so we can use reshaping to get 1-dimensional data. What shape would we expect the input tensor to be? Hint: it still needs to be the same size as the original tensor. \n",
        "\n",
        "Once we have an expectation of what to do, then we can translate it into code. Which of the following options do you thnk would work? \n",
        "\n"
      ],
      "metadata": {
        "id": "HnTzpx1GVHwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reshape(sample_tensor_2,(4,4,1))\n",
        "\n",
        "tf.reshape(sample_tensor_2,(4,4))"
      ],
      "metadata": {
        "id": "4IlbghWAVIG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we want the features in each sample to be one-dimensional, we would go with option two. Finally, we would check the output tensor to make sure it matches our expectations."
      ],
      "metadata": {
        "id": "pT58gaj2cqPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.reshape(sample_tensor_2,(4,4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxPwd6pgeKhq",
        "outputId": "5e2820f6-bdbb-48c8-ef6a-5d7f4a6eff27"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 2  4  6  8]\n",
            " [10 12 14 16]\n",
            " [ 1  3  5  7]\n",
            " [ 9 11 13 15]], shape=(4, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Revisiting Deep Learning\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6TR78IdDij7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives: \n",
        "- Code and optimize a neural network\n",
        "- Adapt a network to new data"
      ],
      "metadata": {
        "id": "6twFHgyZSeiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In previous sections of this course, you have covered neural networks and deep learning for classifying the MNIST dataset. The task was classifying handwritten digits 0-9 based on images. In this section, we will revisit deep learning with Python with text data. \n",
        "\n",
        "We will start with the classificaton problem (student loan vs checking/savings account) from the NLP section of the course, where we used customer complaint data to classify what type of account the complaint was related to. We will use the same embeddings we trained for the final logistic regression problem in that section of the course.\n",
        "\n",
        "First, we will load in the data and split it into training and validation data."
      ],
      "metadata": {
        "id": "RRq8wjQaqiWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_features_df=pd.read_csv('https://github.com/dlab-berkeley/Computational-Social-Science-Training-Program/raw/master/data/embeddings.csv')\n",
        "y=pd.read_csv('https://github.com/dlab-berkeley/Computational-Social-Science-Training-Program/raw/master/data/y.csv')\n",
        "y_vals=y['Product_binary'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(word2vec_features_df, \n",
        "                                                    y_vals, \n",
        "                                                    train_size = .80, \n",
        "                                                    test_size=0.20, \n",
        "                                                    random_state = 10)\n"
      ],
      "metadata": {
        "id": "bMyrg9cv0pDS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we define the model. In Keras, each layer of the model has to be individually specified. This allows significant control over the model, including different parameters for each level.\n",
        "\n",
        "This model has two dense layers with 128 neurons in each, and two dropout layers where 20% of the connections are dropped out for each layer. The final output layer uses a sigmoid activation function to create a final binary output (0 or 1). "
      ],
      "metadata": {
        "id": "qhyFnEKUh_uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NN_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    # A fully connected layer with 128 neurons\n",
        "    model.add(Dense(128, input_dim=301,activation='relu'))\n",
        "\n",
        "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # An output layer with binary classification\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # Compile model with crossentropy\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "colGv5dcuzwP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we fit and evaluate the model."
      ],
      "metadata": {
        "id": "8wH5KqiKiQQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"NN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9AXKsZQwVsR",
        "outputId": "39ae45a8-7b36-4d5e-cbfd-4c626a51233d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 - 2s - loss: 6.9430 - accuracy: 0.6612 - val_loss: 3.5609 - val_accuracy: 0.7800 - 2s/epoch - 99ms/step\n",
            "Epoch 2/10\n",
            "25/25 - 0s - loss: 5.1894 - accuracy: 0.6475 - val_loss: 3.2003 - val_accuracy: 0.7850 - 144ms/epoch - 6ms/step\n",
            "Epoch 3/10\n",
            "25/25 - 0s - loss: 4.7344 - accuracy: 0.6425 - val_loss: 2.3728 - val_accuracy: 0.7850 - 101ms/epoch - 4ms/step\n",
            "Epoch 4/10\n",
            "25/25 - 0s - loss: 4.4107 - accuracy: 0.6625 - val_loss: 2.0520 - val_accuracy: 0.7850 - 114ms/epoch - 5ms/step\n",
            "Epoch 5/10\n",
            "25/25 - 0s - loss: 4.1746 - accuracy: 0.6525 - val_loss: 1.3534 - val_accuracy: 0.7850 - 145ms/epoch - 6ms/step\n",
            "Epoch 6/10\n",
            "25/25 - 0s - loss: 3.3699 - accuracy: 0.7025 - val_loss: 1.9030 - val_accuracy: 0.7850 - 124ms/epoch - 5ms/step\n",
            "Epoch 7/10\n",
            "25/25 - 0s - loss: 3.3367 - accuracy: 0.6712 - val_loss: 2.4567 - val_accuracy: 0.7850 - 102ms/epoch - 4ms/step\n",
            "Epoch 8/10\n",
            "25/25 - 0s - loss: 3.1303 - accuracy: 0.6837 - val_loss: 1.8283 - val_accuracy: 0.7850 - 141ms/epoch - 6ms/step\n",
            "Epoch 9/10\n",
            "25/25 - 0s - loss: 2.6889 - accuracy: 0.6850 - val_loss: 1.5194 - val_accuracy: 0.7850 - 107ms/epoch - 4ms/step\n",
            "Epoch 10/10\n",
            "25/25 - 0s - loss: 2.7983 - accuracy: 0.6463 - val_loss: 1.9814 - val_accuracy: 0.7850 - 108ms/epoch - 4ms/step\n",
            "NN Error: 21.50%\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               38656     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,785\n",
            "Trainable params: 38,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simple neural network with a couple of densely connected layers and a couple of dropout layers. When working with neural nets, it's often a good idea to start with a simple net to make sure the basics of the code work, then gradually create more complicated architectures once the code runs smoothly."
      ],
      "metadata": {
        "id": "EIN6sK82FQxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's use our tensor knowledge to adapt this architecture to another set of data. First, let's load in the MNIST digits dataset (in practice, we would likely be using a dataset more similar to the one n the original model). The MNIST dataset is three dimensions (nsamplesx28x28), so we need to flatten the data for now to create a two dimensional tensor  nsamplesx784 to fit with the neural net we are working on. Note: instead of two classes, the MNIST dataset uses 10 classes (one for each digit 0-9). "
      ],
      "metadata": {
        "id": "LGLS9pEUibTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to [samples][width][height][pixels]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28*28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28*28)\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZTIeDTnBn8o",
        "outputId": "01543509-49a7-435e-9923-613801db3e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the same code from the NN model above. What do you need to change in order to run the same model on the new data? Note which parameters and values you need to change. How does this relate to the differences in the data? Let's edit the code to work with the new data shape and execute it.\n",
        "\n",
        "Hint: use tf.shape() to see the compare the shapes of the MNIST and original dataset"
      ],
      "metadata": {
        "id": "_bP926VQjIJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the lines of code we need to change to make this model work with new data: \n",
        "\n",
        "\n",
        "In line 6: \n",
        "```\n",
        "model.add(Dense(128, input_dim=784,activation='relu')) #change input dim\n",
        "```\n",
        "The embeddings dataset had 301 features, or columns, the new MNIST dataset has 784, so we need to make sure to match the numbers in model architecture. \n",
        "\n",
        "In line 12: \n",
        "\n",
        "```\n",
        "    model.add(Dense(10, activation='softmax')) #change dimension to number of categories\n",
        "```\n",
        "The final layer needs to have 10 categories, rather than two, since there are more classes in the MNIST dataset. In addition, the activation function needs to be changed to softmax.\n",
        "\n",
        "In lne 15:\n",
        "\n",
        "```\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "```\n",
        "\n",
        "Again, because of the number of classes, the loss function used must be categorical cross entropy rather than binary cross entropy. \n",
        "\n",
        "Here is the updated model:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_DtWkyXLfNbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def diff_CNN_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(128, input_dim=784,activation='relu')) #change input dim\n",
        "\n",
        "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    # A fully connected layer with 128 neurons\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.2))\n",
        "    \n",
        "    # An output layer with softmax as in MLP\n",
        "    model.add(Dense(10, activation='softmax')) #change dimension to number of categories\n",
        "    \n",
        "    # Compile model as before in MLP\n",
        "    #change to categorical crossentropy\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = diff_CNN_model()\n",
        "# Fit the model\n",
        "print(X_train.shape)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"NN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "id": "BsgLoMccgRtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n"
      ],
      "metadata": {
        "id": "xTYiVkBM18Fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The logit model from the challenge question in NLP section used to classify the customer complaint data had an accuracy of 78.5%. What is the accuracy of the first neural network model on the same data? Hint: (read the output) Try changing the model to improve accuracy. What configuration gave you the best results? Try changing the parameters of the existing layers, or adding more layers."
      ],
      "metadata": {
        "id": "lZj0IiVYjYtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#original model\n",
        "\n",
        "def NN_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    # A fully connected layer with 128 neurons\n",
        "    model.add(Dense(128, input_dim=301,activation='relu'))\n",
        "\n",
        "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # An output layer with binary classification\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # Compile model with crossentropy\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "    model = NN_model()\n",
        "    \n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"NN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "fpMjqhdt3HKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing Neural Nets\n"
      ],
      "metadata": {
        "id": "23KhRlCwGLSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "- Explore strategies to optimize a neural net\n",
        "- Implement an optimizer with custom settings\n",
        "- Grid search parameters"
      ],
      "metadata": {
        "id": "UOPuwHOBSt2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing neural nets is a key point of using these powerful models effectively, as with any ML models. However, neural nets have many parameters that can be tuned and are a challenge for traditional optmization methods such as grid search.\n",
        "\n",
        "In the previous challenge, we experimented with improving the accuracy of the model. The following strategies can help guide the optmization process for fine-tuning algorithms.\n",
        "\n",
        "1. Feature engineering (refer to Natural Language Processing Notebook)\n",
        "\n",
        "2. Try a smaller network (minimize redundancy) or a larger network (capture more complex relationships)\n",
        "\n",
        "3. Change learning rate\n",
        "4. Use appropriate architecture for the data/task\n",
        "\n",
        "5. Test parameters\n",
        "\n",
        "6. Decrease batch size \n",
        "\n",
        "Depending on the task, data, and neural network used, there may be a significant amount of tuning necessary in order to achieve an optimal result. This is one reason why leveraging existing models that are already optimized can give a huge advantage for language tasks. \n",
        "\n",
        "Further reference this article: https://towardsdatascience.com/optimizing-neural-networks-where-to-start-5a2ed38c8345 \n",
        "\n",
        "\n",
        "For this notebook we will start with changing the learning rate. \n",
        "\n",
        "In previous examples, we passed the optimizer to the compile funciton \n",
        "```\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "```\n",
        "Which uses the default parameters for the function. Now that we are customizing the parameters, we want to use the actual optimizer function, and then pass that optimizer into the .compile() function.\n",
        "\n",
        "```\n",
        "model.compile(....,opt=keras.optimizers.Adam())\n",
        "```\n",
        "\n",
        "Here is the documentation for that function: https://keras.io/api/optimizers/adam/\n",
        "\n",
        "What is the default parameter for learning rate? What are some of the other parameters for the Adam optimizer?"
      ],
      "metadata": {
        "id": "WZjXK0-OGT5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Challenge\n",
        "\n",
        "Test the following learning rates: [.0001,.001,.01,.1]. Which one performs the best? Which one performs the worst?\n",
        "\n"
      ],
      "metadata": {
        "id": "ElzhbM-eOPDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load in data to use for this test\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#cnn classification for neural nets\n",
        "word2vec_features_df=pd.read_csv('https://github.com/dlab-berkeley/Computational-Social-Science-Training-Program/raw/master/data/embeddings.csv')\n",
        "\n",
        "y=pd.read_csv('https://github.com/dlab-berkeley/Computational-Social-Science-Training-Program/raw/master/data/y.csv')\n",
        "y_vals=y['Product_binary'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(word2vec_features_df, \n",
        "                                                    y_vals, \n",
        "                                                    train_size = .80, \n",
        "                                                    test_size=0.20, \n",
        "                                                    random_state = 10)\n",
        "#print(word2vec_features_df.shape)\n",
        "#print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "9DZBPIH2OObp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#solution\n",
        "##1\n",
        "def NN_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(128, input_dim=301,activation='relu')) #change input dim\n",
        "\n",
        "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    # A fully connected layer with 128 neurons\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.2))\n",
        "    \n",
        "    # An output layer with softmax as in MLP\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    adam_opt=Adam(learning_rate=.1)\n",
        "    # Compile model as before in MLP\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "h8LXyHanPz9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN_model()\n",
        "# Fit the model\n",
        "print(X_train.shape)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trjy8DMSQCGj",
        "outputId": "8093332a-e5ac-4148-a973-381b028079ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 301)\n",
            "Epoch 1/10\n",
            "4/4 - 1s - loss: 147.0860 - accuracy: 0.5450 - val_loss: 2.8241 - val_accuracy: 0.7850 - 925ms/epoch - 231ms/step\n",
            "Epoch 2/10\n",
            "4/4 - 0s - loss: 1.7689 - accuracy: 0.5713 - val_loss: 0.5360 - val_accuracy: 0.7850 - 36ms/epoch - 9ms/step\n",
            "Epoch 3/10\n",
            "4/4 - 0s - loss: 0.6445 - accuracy: 0.7862 - val_loss: 0.5481 - val_accuracy: 0.7850 - 33ms/epoch - 8ms/step\n",
            "Epoch 4/10\n",
            "4/4 - 0s - loss: 0.5769 - accuracy: 0.7763 - val_loss: 0.5450 - val_accuracy: 0.7850 - 38ms/epoch - 10ms/step\n",
            "Epoch 5/10\n",
            "4/4 - 0s - loss: 0.5661 - accuracy: 0.7862 - val_loss: 0.5327 - val_accuracy: 0.7850 - 34ms/epoch - 9ms/step\n",
            "Epoch 6/10\n",
            "4/4 - 0s - loss: 0.5716 - accuracy: 0.7850 - val_loss: 0.5289 - val_accuracy: 0.7850 - 34ms/epoch - 8ms/step\n",
            "Epoch 7/10\n",
            "4/4 - 0s - loss: 0.5317 - accuracy: 0.7862 - val_loss: 0.5231 - val_accuracy: 0.7850 - 38ms/epoch - 9ms/step\n",
            "Epoch 8/10\n",
            "4/4 - 0s - loss: 0.5239 - accuracy: 0.7862 - val_loss: 0.5207 - val_accuracy: 0.7850 - 36ms/epoch - 9ms/step\n",
            "Epoch 9/10\n",
            "4/4 - 0s - loss: 0.5213 - accuracy: 0.7862 - val_loss: 0.5206 - val_accuracy: 0.7850 - 49ms/epoch - 12ms/step\n",
            "Epoch 10/10\n",
            "4/4 - 0s - loss: 0.5182 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7850 - 44ms/epoch - 11ms/step\n",
            "CNN Error: 21.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huggingface"
      ],
      "metadata": {
        "id": "v5Ovl5RF2DjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "- Explore tasks and data available in Huggingface transformers\n",
        "- Choose an appropriate language task\n",
        "- Implement a transformer on local data"
      ],
      "metadata": {
        "id": "DRXZt7DhS7mR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In reality, these models  require significant data and computational power, which can exceed the resources available to the analyst. We can circumvent this problem by using pre-trained models. Like a pre-trained embedding model, pre-trained models are trained on a large dataset. While this may not perfectly align with the data or task you have, it can help create a more robust system that can be fine-tuned to your data and goals.\n",
        "\n",
        "[Huggingface](https://huggingface.co/models) is a set of pretrained models from a variety of datasets and sources with an easy-to-use interface. In this section, we will explore the use of the Huggingface library to streamline language task processing.\n",
        "\n"
      ],
      "metadata": {
        "id": "glKdUE_CEw7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install the transformers library\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE52xADz3Py-",
        "outputId": "bc902d9a-72f8-459e-d3a5-338322f89e53"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 35.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simplest strategy is to use the pipeline method, where you select the task and the pre-trained model (there are multiple models available for many of the tasks)"
      ],
      "metadata": {
        "id": "WygeyX2MQo8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\") \n"
      ],
      "metadata": {
        "id": "V9pq4nvXSnMh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183,
          "referenced_widgets": [
            "7a74a3c514144ee3a3bf386fbb3dbc8e",
            "13b694993ab747ffa0b563134cc361b3",
            "112c02c165ad4ea992314b4b5fbc645d",
            "fc5dbb1d102d41cfa0c20bbbb3c38f0e",
            "15558253f80d45d0801a0f93beb9e00c",
            "94ec5dafdb1d4b08ac8c5f08259bae65",
            "5a0e9ae8bca1429e875d8e359d809f15",
            "37824a7ff684403189f05376eb56209d",
            "facfb260eaa147018472e1fa2f2f1332",
            "5610b039845d4274ac54c018e18171a9",
            "1ebcefab8184477f961812e2764ebf57",
            "1a82642ae5e34f43832b9c9cff277944",
            "f0b3f3cf63f74f0cac5d84cfb3acc1bb",
            "5124c1bb783c45a2886c742aa79bcf87",
            "1205c7b7d6f641c38c33444a382d43b1",
            "659fbe0a060b496cbee4a0a1be51a925",
            "2e1650fe6592464fa83082995a768901",
            "00b4d9bc69fa4ef29f8a5336f64ea449",
            "49ffd5892b0947c7bd49fc1b7630a01a",
            "7552ea24d6754ebab80240c39dbf29f0",
            "de1699df1e164930bf8852efdced8536",
            "b451b768dc5e477dabe14fc7a3f0f5e1",
            "a226f52e8f714f548bddd8a5269e5f63",
            "c672d449f6be4a2687700fded7dc3494",
            "4ab70c84ac9146358226cb827e20c6db",
            "cd1abde25fec4a99ace1a06625be18b8",
            "e278b88b2bd2458bb773c2ee41192863",
            "3e8336756689478a9da33f53fa58f1ea",
            "3e633e8fc58d4c3cacaf772135bfe096",
            "ce5685da74d546119f39afb98c589deb",
            "62285f407a8746ab9f282fbad75995fb",
            "8b028e0255c84020b7630ba7ea5f1d15",
            "20cf93c3b9ef4d7c8aa347792bbd57ff",
            "0b7b6c4d914e48f7b367514ea5ad4ab9",
            "70aed85c10474e24afee02f4d0ce191c",
            "34916cb450b24154b37f28c38760f0e5",
            "6d653345f271408d892c331643aad030",
            "8551d92d168e43538415c39563c079a7",
            "cb522df2753f4f91bf2a192069f34bde",
            "be861d7f0c854931b13d4fbe564aac2d",
            "2da71e7640de40138b657387888ed34f",
            "e237e7f86eee47c9958d6ff5595c13f4",
            "a7d7699eed024c2ebfebde18e9135c38",
            "2a373404de174f7e935246e403757a16"
          ]
        },
        "outputId": "8d1ee833-783c-49df-9c68-89116bf6697d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a74a3c514144ee3a3bf386fbb3dbc8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a82642ae5e34f43832b9c9cff277944",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a226f52e8f714f548bddd8a5269e5f63",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b7b6c4d914e48f7b367514ea5ad4ab9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key to using these models, since the preprocessing is built in, is understanding the format of the data necessary for the model. This model takes the raw text as input rather than the word embeddings, so let's reload our data appropriately."
      ],
      "metadata": {
        "id": "cdXQGdLgQ9sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfpb=pd.read_csv('https://raw.githubusercontent.com/dlab-berkeley/Computational-Social-Science-Training-Program/master/data/CFPB%202020%20Complaints.csv')\n",
        "complaints=cfpb['Consumer complaint narrative']\n",
        "complaints=complaints[~complaints.isna()]\n",
        "classifier(complaints.values[0])\n",
        "print(complaints.values[0])"
      ],
      "metadata": {
        "id": "Iahhf3AEUGBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975e2116-2ef3-450c-919c-fa3524a99c75"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviewed my credit report in XX/XX/XXXX and noticed a lot of errors, inconsistent, and incorrect information. Sent a letter to Equifax on XX/XX/XXXX via mail asking them for an investigation and to verify all the dates and amounts were correct and fix the incorrect reporting on my credit. They did not respond at all so I sent another letter on XX/XX/XXXX via mail, again asking for an investigation and proof. They still didnt respond to that letter so I sent a third letter on XX/XX/XXXX certified mail so I have proof that they signed for my letter.\n",
            "\n",
            "Last week I received two letters from Equifax dated XX/XX/XXXX on the same day. The said that they could not locate my credit file and needed me to send proof of identification and address. With all three letters I sent a copy of my Arizona drivers license and my XXXX direct deposit sub as my proof of address. The second letter said that they received my request to be removed from the promotions list and that it was added to my credit file. How did they find my file to add the restriction if they couldnt find my credit file in regards to investigation purposes?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then use the pipeline on the example data, and look at the results."
      ],
      "metadata": {
        "id": "7_rQGYoPRNon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(10):\n",
        "  print(complaints.values[k])\n",
        "  print(classifier(complaints.values[k]))"
      ],
      "metadata": {
        "id": "Thjw7tTaRSgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06d06fa-91f9-4647-fb27-494fc4e698ed"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'NEGATIVE', 'score': 0.9993847608566284}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.9992923736572266}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.9986603260040283}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.9974887371063232}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.9996302127838135}]\n",
            "[{'label': 'POSITIVE', 'score': 0.9877626895904541}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.995735764503479}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.9988757967948914}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.9987154006958008}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.9994825124740601}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you might expect, the complaints dataset has mostly negative values. While this is somewhat of a trivial example, it highlights how in just a few lines of code and no preprocessing we can implement a model on our own data. While this doesn't work for every task, for example the specific classification task that we were working with above, this is a valuable and powerful tool for quick, out-of-the-box models that don't take very long to initialize and tune."
      ],
      "metadata": {
        "id": "eGFiOhimXOYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge \n",
        "\n",
        "Let's practice with another task  from the [huggingface](https://huggingface.co/docs/transformers/task_summary). \n",
        "\n",
        "Let's say we want to check our data for grammatical correctness. We will use the CoLA model (\"textattack/distilbert-base-uncased-CoLA\") in the Text Classification pipeline ('text-classification') What is the grammatical correctness of each of the first 15 entries in the cfpb dataset?\n"
      ],
      "metadata": {
        "id": "GP_oJhO0WcJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#solution\n",
        "#classifier = pipeline(\"text-classification\", model = \"textattack/distilbert-base-uncased-CoLA\")\n",
        "#classifier(\"I went to the bus.\")\n"
      ],
      "metadata": {
        "id": "0cnh_0zQjfEf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are thousands of models on huggingface that can be used for a variety of language tasks. This can be a great way to use the models already available to increase our modeling power. "
      ],
      "metadata": {
        "id": "n_pNEaqhpKHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Steps\n",
        "\n",
        "This lab has introduced Colab as a way to use GPUs to speed up processing power and explored further applications of deep learning to natural language processing. \n",
        "\n",
        "In practice, using deep learning for computational social science requires building on the foundational concepts covered in this notebook to implement models with more complicated data and architecture. However, there are many strategies can help you navigate the model ecosystem, some of which we will discuss here: \n",
        "\n",
        "1. Documentation (and other resources like tutorials) is a goldmine of information for implementing particular algorithms and completing specific tasks. This is one reason why reading and translating code written by others is a key skill. \n",
        "\n",
        "2. Debugging and interpreting error messages, as well as leveraging online resources in order to resolve them, is another key concept. Resources like documentation and Stack Overflow help solve common errors and get code working faster. In addition, checking your code as you go and forming expectations of the results at each step will also help you to code smoothly.\n",
        "\n",
        "3. Computational resources are important for running complex models. Google Colab has access to GPUs, but does have limitations for large and extended jobs. In those cases, options are: [add further resources here]\n",
        "\n",
        "4. Further resources [add some books on deep learning and nlp]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0yLbtugXYBqV"
      }
    }
  ]
}